
@article{hernandez_best_2023,
	title = {On the {Best} {Way} to {Cluster} {NCI}-60 {Molecules}.},
	volume = {13},
	issn = {2218-273X},
	doi = {10.3390/biom13030498},
	abstract = {Machine learning-based models have been widely used in the early drug-design pipeline. To validate these models, cross-validation strategies have been  employed, including those using clustering of molecules in terms of their  chemical structures. However, the poor clustering of compounds will compromise  such validation, especially on test molecules dissimilar to those in the training  set. This study aims at finding the best way to cluster the molecules screened by  the National Cancer Institute (NCI)-60 project by comparing hierarchical,  Taylor-Butina, and uniform manifold approximation and projection (UMAP)  clustering methods. The best-performing algorithm can then be used to generate  clusters for model validation strategies. This study also aims at measuring the  impact of removing outlier molecules prior to the clustering step. Clustering  results are evaluated using three well-known clustering quality metrics. In  addition, we compute an average similarity matrix to assess the quality of each  cluster. The results show variation in clustering quality from method to method.  The clusters obtained by the hierarchical and Taylor-Butina methods are more  computationally expensive to use in cross-validation strategies, and both cluster  the molecules poorly. In contrast, the UMAP method provides the best quality, and  therefore we recommend it to analyze this highly valuable dataset.},
	language = {eng},
	number = {3},
	journal = {Biomolecules},
	author = {Hernández, Saiveth and Ballester, Pedro J.},
	month = mar,
	year = {2023},
	pmid = {36979433},
	pmcid = {PMC10046274},
	note = {Place: Switzerland},
	keywords = {*Algorithms, *Machine Learning, Cluster Analysis, Drug Design, NCI-60 panel, National Cancer Institute (U.S.), United States, clustering, model validation, small molecules},
}

@article{ma_graph_2023,
	title = {Graph {Inductive} {Biases} in {Transformers} without {Message} {Passing}},
	doi = {10.48550/arXiv.2305.17589},
	journal = {arXiv e-prints},
	author = {Ma, Liheng and Lin, Chen and Lim, Derek and Romero-Soriano, Adriana and Dokania, Puneet K. and Coates, Mark and Torr, Philip and Lim, Ser-Nam},
	month = may,
	year = {2023},
	note = {\_eprint: 2305.17589},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	pages = {arXiv:2305.17589},
}

@article{menegaux_self-attention_2023,
	title = {Self-{Attention} in {Colors}: {Another} {Take} on {Encoding} {Graph} {Structure} in {Transformers}},
	doi = {10.48550/arXiv.2304.10933},
	journal = {arXiv e-prints},
	author = {Menegaux, Romain and Jehanno, Emmanuel and Selosse, Margot and Mairal, Julien},
	month = apr,
	year = {2023},
	note = {\_eprint: 2304.10933},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:2304.10933},
}

@article{rampasek_recipe_2022,
	title = {Recipe for a {General}, {Powerful}, {Scalable} {Graph} {Transformer}},
	doi = {10.48550/arXiv.2205.12454},
	journal = {arXiv e-prints},
	author = {Rampášek, Ladislav and Galkin, Mikhail and Dwivedi, Vijay Prakash and Luu, Anh Tuan and Wolf, Guy and Beaini, Dominique},
	month = may,
	year = {2022},
	note = {\_eprint: 2205.12454},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:2205.12454},
}

@article{provost_case_2001,
	title = {The {Case} {Against} {Accuracy} {Estimation} for {Comparing} {Induction} {Algorithms}},
	journal = {Proceedings of the Fifteenth International Conference on Machine Learning},
	author = {Provost, Foster and Fawcett, Tom and Kohavi, Ron},
	month = apr,
	year = {2001},
}

@article{ward_hierarchical_1963,
	title = {Hierarchical {Grouping} to {Optimize} an {Objective} {Function}},
	volume = {58},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1963.10500845},
	doi = {10.1080/01621459.1963.10500845},
	number = {301},
	journal = {Journal of the American Statistical Association},
	author = {Ward, Joe H.},
	year = {1963},
	note = {Publisher: Taylor \& Francis
\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1963.10500845},
	pages = {236--244},
}

@incollection{keogh_curse_2010,
	address = {Boston, MA},
	title = {Curse of {Dimensionality}},
	isbn = {978-0-387-30164-8},
	url = {https://doi.org/10.1007/978-0-387-30164-8_192},
	booktitle = {Encyclopedia of {Machine} {Learning}},
	publisher = {Springer US},
	author = {Keogh, Eamonn and Mueen, Abdullah},
	editor = {Sammut, Claude and Webb, Geoffrey I.},
	year = {2010},
	doi = {10.1007/978-0-387-30164-8_192},
	pages = {257--258},
}

@article{hosseini_using_1997,
	title = {Using {Artificial} {Neural} {Networks} {To} {Classify} the {Activity} of {Capsaicin} and {Its} {Analogues}},
	volume = {37},
	issn = {0095-2338},
	url = {https://doi.org/10.1021/ci9700384},
	doi = {10.1021/ci9700384},
	number = {6},
	journal = {Journal of Chemical Information and Computer Sciences},
	author = {Hosseini, M. and Maddalena, D. J. and Spence, I.},
	month = nov,
	year = {1997},
	note = {Publisher: American Chemical Society},
	pages = {1129--1137},
}

@article{zhong_count-based_2023,
	title = {Count-{Based} {Morgan} {Fingerprint}: {A} {More} {Efficient} and {Interpretable} {Molecular} {Representation} in {Developing} {Machine} {Learning}-{Based} {Predictive} {Regression} {Models} for {Water} {Contaminants}’ {Activities} and {Properties}},
	issn = {0013-936X},
	doi = {10.1021/acs.est.3c02198},
	journal = {Environmental Science \& Technology},
	author = {Zhong, Shifa and Guan, Xiaohong},
	month = jul,
	year = {2023},
}

@article{allen-zhu_learning_2018,
	title = {Learning and {Generalization} in {Overparameterized} {Neural} {Networks}, {Going} {Beyond} {Two} {Layers}},
	doi = {10.48550/arXiv.1811.04918},
	journal = {arXiv e-prints},
	author = {Allen-Zhu, Zeyuan and Li, Yuanzhi and Liang, Yingyu},
	month = nov,
	year = {2018},
	note = {\_eprint: 1811.04918},
	keywords = {Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control, Statistics - Machine Learning},
	pages = {arXiv:1811.04918},
}

@article{sagawa_investigation_2020,
	title = {An {Investigation} of {Why} {Overparameterization} {Exacerbates} {Spurious} {Correlations}},
	doi = {10.48550/arXiv.2005.04345},
	journal = {arXiv e-prints},
	author = {Sagawa, Shiori and Raghunathan, Aditi and Koh, Pang Wei and Liang, Percy},
	month = may,
	year = {2020},
	note = {\_eprint: 2005.04345},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:2005.04345},
}

@article{zhang_understanding_2016,
	title = {Understanding deep learning requires rethinking generalization},
	doi = {10.48550/arXiv.1611.03530},
	journal = {arXiv e-prints},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	month = nov,
	year = {2016},
	note = {\_eprint: 1611.03530},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:1611.03530},
}

@article{rocks_bias-variance_2022,
	title = {Bias-variance decomposition of overparameterized regression with random linear features},
	volume = {106},
	doi = {10.1103/PhysRevE.106.025304},
	number = {2},
	journal = {{\textbackslash}pre},
	author = {Rocks, Jason W. and Mehta, Pankaj},
	month = aug,
	year = {2022},
	note = {\_eprint: 2203.05443},
	keywords = {Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural Networks, Statistics - Machine Learning},
	pages = {025304},
}

@techreport{european_communities_regulation_2006,
	title = {Regulation ({EC}) {No} 1907/2006 of the {European} {Parliament} and of the {Council} of 18 {December} 2006 concerning the {Registration}, {Evaluation}, {Authorisation} and {Restriction} of {Chemicals} ({REACH}), establishing a {European} {Chemicals} {Agency}, amending {Directive} 1999/45/{EC} and repealing {Council} {Regulation} ({EEC}) {No} 793/93 and {Commission} {Regulation} ({EC}) {No} 1488/94 as well as {Council} {Directive} 76/769/{EEC} and {Commission} {Directives} 91/155/{EEC}, 93/67/{EEC}, 93/105/{EC} and 2000/21/{EC}},
	author = {{European Communities}},
	year = {2006},
	pages = {1--849},
}

@article{hu_open_2020,
	title = {Open {Graph} {Benchmark}: {Datasets} for {Machine} {Learning} on {Graphs}},
	doi = {10.48550/arXiv.2005.00687},
	journal = {arXiv e-prints},
	author = {Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
	month = may,
	year = {2020},
	note = {\_eprint: 2005.00687},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
	pages = {arXiv:2005.00687},
}

@article{guo_calibration_2017,
	title = {On {Calibration} of {Modern} {Neural} {Networks}},
	doi = {10.48550/arXiv.1706.04599},
	journal = {arXiv e-prints},
	author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
	month = jun,
	year = {2017},
	note = {\_eprint: 1706.04599},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:1706.04599},
}

@inproceedings{flach_classification_2007,
	title = {On classification, ranking, and probability estimation.},
	author = {Flach, Peter and Matsubara, Edson},
	month = jan,
	year = {2007},
}

@article{xiong_layer_2020,
	title = {On {Layer} {Normalization} in the {Transformer} {Architecture}},
	doi = {10.48550/arXiv.2002.04745},
	journal = {arXiv e-prints},
	author = {Xiong, Ruibin and Yang, Yunchang and He, Di and Zheng, Kai and Zheng, Shuxin and Xing, Chen and Zhang, Huishuai and Lan, Yanyan and Wang, Liwei and Liu, Tie-Yan},
	month = feb,
	year = {2020},
	note = {\_eprint: 2002.04745},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:2002.04745},
}

@techreport{oecd_overview_2020,
	address = {Paris, France},
	title = {Overview of {Concepts} and {Available} {Guidance} related to {Integrated} {Approaches} to {Testing} and {Assessment} ({IATA})},
	url = {https://www.oecd.org/chemicalsafety/risk-assessment/concepts-and-available-guidance-related-to-integrated-approaches-to-testing-and-assessment.pdf},
	language = {English},
	number = {329},
	author = {{OECD}},
	year = {2020},
}

@article{elnaggar_prottrans_2020,
	title = {{ProtTrans}: {Towards} {Cracking} the {Language} of {Life}'s {Code} {Through} {Self}-{Supervised} {Deep} {Learning} and {High} {Performance} {Computing}},
	doi = {10.48550/arXiv.2007.06225},
	journal = {arXiv e-prints},
	author = {Elnaggar, Ahmed and Heinzinger, Michael and Dallago, Christian and Rihawi, Ghalia and Wang, Yu and Jones, Llion and Gibbs, Tom and Feher, Tamas and Angerer, Christoph and Steinegger, Martin and Bhowmik, Debsindhu and Rost, Burkhard},
	month = jul,
	year = {2020},
	note = {\_eprint: 2007.06225},
	keywords = {Computer Science - Computation and Language, Computer Science - Distributed, Computer Science - Machine Learning, Parallel, Statistics - Machine Learning, and Cluster Computing},
	pages = {arXiv:2007.06225},
}

@article{radford_learning_2021,
	title = {Learning {Transferable} {Visual} {Models} {From} {Natural} {Language} {Supervision}},
	doi = {10.48550/arXiv.2103.00020},
	journal = {arXiv e-prints},
	author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and Krueger, Gretchen and Sutskever, Ilya},
	month = feb,
	year = {2021},
	note = {\_eprint: 2103.00020},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	pages = {arXiv:2103.00020},
}

@article{parmar_image_2018,
	title = {Image {Transformer}},
	doi = {10.48550/arXiv.1802.05751},
	journal = {arXiv e-prints},
	author = {Parmar, Niki and Vaswani, Ashish and Uszkoreit, Jakob and Kaiser, Łukasz and Shazeer, Noam and Ku, Alexander and Tran, Dustin},
	month = feb,
	year = {2018},
	note = {\_eprint: 1802.05751},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {arXiv:1802.05751},
}

@article{tennant_classification_1991,
	title = {Classification according to chemical structure, mutagenicity to {Salmonella} and level of carcinogenicity of a further 39 chemicals tested for carcinogenicity by the {U}.{S}. {National} {Toxicology} {Program}},
	volume = {257},
	copyright = {1991},
	issn = {0165-1110},
	abstract = {This paper is an extension of compilations published previously in this journal. (Ashby and Tennant, 1988; Ashby et al., 1989). A summary of the rodent carcinogenicity bioassay data on a further 39 chemicals tested by the U.S. National Toxicology Program (NTP) is presented. An evaluation of each chemical for structural alerts to DNA-reactivity is also provided, together with a summary of its mutagenicity to Salmonella. Chemicals with an aliphatic nitro group (−C−NO 2) have been added to the composite structure of DNA-reactive sub-groups. The 39 chemicals were numbered and evaluated as an extension of the earlier analysis of 264 NTP chemicals. The activity patterns and conclusions derived from the earlier studies are followed by these 39 chemicals, albeit a detailed analysis of the total database of 301 chemicals is reserved for the succeeding paper.},
	language = {eng},
	number = {3},
	journal = {Mutation research. Reviews in genetic toxicology},
	author = {Tennant, Raymond W. and Ashby, John},
	year = {1991},
	note = {Place: Amsterdam
Publisher: Elsevier B.V},
	keywords = {Chemical mutagenesis, Medical sciences, Toxicology},
	pages = {209--227},
}

@article{rousseeuw_silhouettes_1987,
	title = {Silhouettes: {A} graphical aid to the interpretation and validation of cluster analysis},
	volume = {20},
	issn = {0377-0427},
	url = {https://www.sciencedirect.com/science/article/pii/0377042787901257},
	doi = {https://doi.org/10.1016/0377-0427(87)90125-7},
	abstract = {A new graphical display is proposed for partitioning techniques. Each cluster is represented by a so-called silhouette, which is based on the comparison of its tightness and separation. This silhouette shows which objects lie well within their cluster, and which ones are merely somewhere in between clusters. The entire clustering is displayed by combining the silhouettes into a single plot, allowing an appreciation of the relative quality of the clusters and an overview of the data configuration. The average silhouette width provides an evaluation of clustering validity, and might be used to select an ‘appropriate’ number of clusters.},
	journal = {Journal of Computational and Applied Mathematics},
	author = {Rousseeuw, Peter J.},
	year = {1987},
	keywords = {Graphical display, classification, cluster analysis, clustering validity},
	pages = {53--65},
}

@article{lin_survey_2021,
	title = {A {Survey} of {Transformers}},
	doi = {10.48550/arXiv.2106.04554},
	journal = {arXiv e-prints},
	author = {Lin, Tianyang and Wang, Yuxin and Liu, Xiangyang and Qiu, Xipeng},
	month = jun,
	year = {2021},
	note = {\_eprint: 2106.04554},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	pages = {arXiv:2106.04554},
}

@inproceedings{wu_kdlgt_2023,
	series = {{IJCAI} '23},
	title = {{KDLGT}: a linear graph transformer framework via kernel decomposition approach},
	isbn = {978-1-956792-03-4},
	url = {https://doi.org/10.24963/ijcai.2023/263},
	doi = {10.24963/ijcai.2023/263},
	abstract = {In recent years, graph Transformers (GTs) have been demonstrated as a robust architecture for a wide range of graph learning tasks. However, the quadratic complexity of GTs limits their scalability on large-scale data, in comparison to Graph Neural Networks (GNNs). In this work, we propose the Kernel Decomposition Linear Graph Transformer (KDLGT), an accelerating framework for building scalable and powerful GTs. KDLGT employs the kernel decomposition approach to rearrange the order of matrix multiplication, thereby reducing complexity to linear. Additionally, it categorizes GTs into three distinct types and provides tailored accelerating methods for each category to encompass all types of GTs. Furthermore, we provide a theoretical analysis of the performance gap between KDLGT and self-attention to ensure its effectiveness. Under this framework, we select two representative GTs to design our models. Experiments on both real-world and synthetic datasets indicate that KDLGT not only achieves state-of-the-art performance on various datasets but also reaches an acceleration ratio of approximately 10 on graphs of certain sizes.},
	booktitle = {Proceedings of the {Thirty}-{Second} {International} {Joint} {Conference} on {Artificial} {Intelligence}},
	author = {Wu, Yi and Xu, Yanyang and Zhu, Wenhao and Song, Guojie and Lin, Zhouchen and Wang, Liang and Liu, Shaoguo},
	year = {2023},
	note = {Place: , Macao, P.R.China,},
}

@inproceedings{deng_polynormer_2024,
	title = {Polynormer: {Polynomial}-{Expressive} {Graph} {Transformer} in {Linear} {Time}},
	url = {https://openreview.net/forum?id=hmv1LpNfXa},
	booktitle = {The {Twelfth} {International} {Conference} on {Learning} {Representations}},
	author = {Deng, Chenhui and Yue, Zichao and Zhang, Zhiru},
	year = {2024},
}

@inproceedings{nguyen_improving_2022,
	title = {Improving {Transformer} with an {Admixture} of {Attention} {Heads}},
	volume = {35},
	url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b2e4edd53059e24002a0c916d75cc9a3-Paper-Conference.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Nguyen, Tan and Nguyen, Tam and Do, Hai and Nguyen, Khai and Saragadam, Vishwanath and Pham, Minh and Nguyen, Khuong Duy and Ho, Nhat and Osher, Stanley},
	editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
	year = {2022},
	pages = {27937--27952},
}

@book{oecd_guidance_2014,
	title = {Guidance {Document} on the {Validation} of ({Quantitative}) {Structure}-{Activity} {Relationship} [({Q}){SAR}] {Models}},
	url = {https://www.oecd-ilibrary.org/content/publication/9789264085442-en},
	author = {OECD},
	year = {2014},
	note = {Type: doi:https://doi.org/10.1787/9789264085442-en},
}

@article{mcinnes_umap_2018,
	title = {{UMAP}: {Uniform} {Manifold} {Approximation} and {Projection} for {Dimension} {Reduction}},
	doi = {10.48550/arXiv.1802.03426},
	journal = {arXiv e-prints},
	author = {McInnes, Leland and Healy, John and Melville, James},
	month = feb,
	year = {2018},
	note = {\_eprint: 1802.03426},
	keywords = {Computer Science - Computational Geometry, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:1802.03426},
}

@article{huang_short_2022,
	title = {A {Short} {Tutorial} on {The} {Weisfeiler}-{Lehman} {Test} {And} {Its} {Variants}},
	doi = {10.48550/arXiv.2201.07083},
	journal = {arXiv e-prints},
	author = {Huang, Ningyuan and Villar, Soledad},
	month = jan,
	year = {2022},
	note = {\_eprint: 2201.07083},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:2201.07083},
}

@inproceedings{leman_reduction_2018,
	title = {{THE} {REDUCTION} {OF} {A} {GRAPH} {TO} {CANONICAL} {FORM} {AND} {THE} {ALGEBRA} {WHICH} {APPEARS} {THEREIN}},
	url = {https://api.semanticscholar.org/CorpusID:49579538},
	author = {Leman, Adrien},
	year = {2018},
}

@inproceedings{kanatsoulis_graph_2023,
	title = {Graph {Neural} {Networks} {Are} {More} {Powerful} {Than} we {Think}},
	url = {https://openreview.net/forum?id=lgYzzQ0fX5D},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Kanatsoulis, Charilaos and Ribeiro, Alejandro},
	year = {2023},
}

@inproceedings{xu_how_2019,
	title = {How powerful are graph neural networks?},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
	year = {2019},
}

@article{zhao_are_2023,
	title = {Are {More} {Layers} {Beneficial} to {Graph} {Transformers}?},
	doi = {10.48550/arXiv.2303.00579},
	journal = {arXiv e-prints},
	author = {Zhao, Haiteng and Ma, Shuming and Zhang, Dongdong and Deng, Zhi-Hong and Wei, Furu},
	month = mar,
	year = {2023},
	note = {\_eprint: 2303.00579},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:2303.00579},
}

@inproceedings{dietterich_ensemble_2000,
	address = {Berlin, Heidelberg},
	title = {Ensemble {Methods} in {Machine} {Learning}},
	isbn = {978-3-540-45014-6},
	abstract = {Ensemble methods are learning algorithms that construct a set of classifiers and then classify new data points by taking a (weighted) vote of their predictions. The original ensemble method is Bayesian averaging, but more recent algorithms include error-correcting output coding, Bagging, and boosting. This paper reviews these methods and explains why ensembles can often perform better than any single classifier. Some previous studies comparing ensemble methods are reviewed, and some new experiments are presented to uncover the reasons that Adaboost does not overfit rapidly.},
	booktitle = {Multiple {Classifier} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dietterich, Thomas G.},
	year = {2000},
	pages = {1--15},
}

@article{rokach_ensemble-based_2010,
	title = {Ensemble-based classifiers},
	volume = {33},
	issn = {1573-7462},
	url = {https://doi.org/10.1007/s10462-009-9124-7},
	doi = {10.1007/s10462-009-9124-7},
	abstract = {The idea of ensemble methodology is to build a predictive model by integrating multiple models. It is well-known that ensemble methods can be used for improving prediction performance. Researchers from various disciplines such as statistics and AI considered the use of ensemble methodology. This paper, review existing ensemble techniques and can be served as a tutorial for practitioners who are interested in building ensemble based systems.},
	number = {1},
	journal = {Artificial Intelligence Review},
	author = {Rokach, Lior},
	month = feb,
	year = {2010},
	pages = {1--39},
}

@article{mienye_survey_2022,
	title = {A {Survey} of {Ensemble} {Learning}: {Concepts}, {Algorithms}, {Applications}, and {Prospects}},
	volume = {10},
	doi = {10.1109/ACCESS.2022.3207287},
	journal = {IEEE Access},
	author = {Mienye, Ibomoiye Domor and Sun, Yanxia},
	year = {2022},
	keywords = {Algorithms, Bagging, Boosting, Classification algorithms, Computational modeling, Learning systems, Machine learning, Machine learning algorithms, Prediction algorithms, classification, ensemble learning, fraud detection, machine learning, medical diagnosis},
	pages = {99129--99149},
}

@article{wang_prediction_2023,
	title = {Prediction of the effects of small molecules on the gut microbiome using machine learning method integrating with optimal molecular features.},
	volume = {24},
	copyright = {© 2023. BioMed Central Ltd., part of Springer Nature.},
	issn = {1471-2105},
	doi = {10.1186/s12859-023-05455-1},
	abstract = {BACKGROUND: The human gut microbiome (HGM), consisting of trillions of microorganisms, is crucial to human health. Adverse drug use is one of the most  important causes of HGM disorder. Thus, it is necessary to identify drugs or  compounds with anti-commensal effects on HGM in the early drug discovery stage.  This study proposes a novel anti-commensal effects classification using a machine  learning method and optimal molecular features. To improve the prediction  performance, we explored combinations of six fingerprints and three descriptors  to filter the best characterization as molecular features. RESULTS: The final  consensus model based on optimal features yielded the F1-score of 0.725 ± 0.014,  ACC of 82.9 ± 0.7\%, and AUC of 0.791 ± 0.009 for five-fold cross-validation. In  addition, this novel model outperformed the prior studies by using the same  algorithm. Furthermore, the important chemical descriptors and misclassified  anti-commensal compounds are analyzed to better understand and interpret the  model. Finally, seven structural alerts responsible for the chemical  anti-commensal effect are identified, implying valuable information for drug  design. CONCLUSION: Our study would be a promising tool for screening  anti-commensal compounds in the early stage of drug discovery and assessing the  potential risks of these drugs in vivo.},
	language = {eng},
	number = {1},
	journal = {BMC bioinformatics},
	author = {Wang, Binyou and Guo, Jianmin and Liu, Xiaofeng and Yu, Yang and Wu, Jianming and Wang, Yiwei},
	month = sep,
	year = {2023},
	pmid = {37697256},
	pmcid = {PMC10496404},
	note = {Place: England},
	keywords = {*Gastrointestinal Microbiome, Algorithms, Anti-commensal effect, Consensus, Consensus model, Human gut microbiome, Humans, Machine Learning, Machine learning, Molecular features, Research Design},
	pages = {338},
}

@article{abdi_holms_2010,
	title = {Holm’s sequential {Bonferroni} procedure},
	volume = {1},
	number = {8},
	journal = {Encyclopedia of research design},
	author = {Abdi, Hervé},
	year = {2010},
	note = {Publisher: Thousand Oaks, California},
	pages = {1--8},
}

@article{holm_simple_1979,
	title = {A simple sequentially rejective multiple test procedure},
	journal = {Scandinavian journal of statistics},
	author = {Holm, Sture},
	year = {1979},
	note = {Publisher: JSTOR},
	pages = {65--70},
}

@article{li_deepames_2023,
	title = {{DeepAmes}: {A} deep learning-powered {Ames} test predictive model with potential for regulatory application.},
	volume = {144},
	copyright = {Published by Elsevier Inc.},
	issn = {1096-0295 0273-2300},
	doi = {10.1016/j.yrtph.2023.105486},
	abstract = {The Ames assay is required by the regulatory agencies worldwide to assess the mutagenic potential risk of consumer products. As well as this in vitro assay, in  silico approaches have been widely used to predict Ames test results as outlined  in the International Council for Harmonization (ICH) guidelines. Building on this  in silico approach, here we describe DeepAmes, a high performance and robust  model developed with a novel deep learning (DL) approach for potential utility in  regulatory science. DeepAmes was developed with a large and consistent Ames  dataset ({\textgreater}10,000 compounds) and was compared with other five standard Machine  Learning (ML) methods. Using a test set of 1,543 compounds, DeepAmes was the best  performer in predicting the outcome of Ames assay. In addition, DeepAmes yielded  the best and most stable performance up to when compounds were {\textgreater}30\% outside of  the applicability domain (AD). Regarding the potential for regulatory  application, a revised version of DeepAmes with a much-improved sensitivity of  0.87 from 0.47. In conclusion, DeepAmes provides a DL-powered Ames test  predictive model for predicting the results of Ames tests; with its defined AD  and clear context of use, DeepAmes has potential for utility in regulatory  application.},
	language = {eng},
	journal = {Regulatory toxicology and pharmacology : RTP},
	author = {Li, Ting and Liu, Zhichao and Thakkar, Shraddha and Roberts, Ruth and Tong, Weida},
	month = oct,
	year = {2023},
	pmid = {37633327},
	note = {Place: Netherlands},
	keywords = {*Deep Learning, Ames test, Applicability domain, Context of use, Deep learning, Machine learning, Mutagenesis, Mutagenicity, Mutagenicity Tests/methods, Mutagens/toxicity, QSAR},
	pages = {105486},
}

@inproceedings{niculescu-mizil_predicting_2005,
	title = {Predicting good probabilities with supervised learning},
	booktitle = {Proceedings of the 22nd international conference on {Machine} learning},
	author = {Niculescu-Mizil, Alexandru and Caruana, Rich},
	year = {2005},
	pages = {625--632},
}

@inproceedings{gal_dropout_2016,
	address = {New York, New York, USA},
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Dropout as a {Bayesian} {Approximation}: {Representing} {Model} {Uncertainty} in {Deep} {Learning}},
	volume = {48},
	url = {https://proceedings.mlr.press/v48/gal16.html},
	abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.},
	booktitle = {Proceedings of {The} 33rd {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Gal, Yarin and Ghahramani, Zoubin},
	editor = {Balcan, Maria Florina and Weinberger, Kilian Q.},
	month = jun,
	year = {2016},
	pages = {1050--1059},
}

@article{hicks_evaluation_2022,
	title = {On evaluation metrics for medical applications of artificial intelligence.},
	volume = {12},
	copyright = {© 2022. The Author(s).},
	issn = {2045-2322},
	doi = {10.1038/s41598-022-09954-8},
	abstract = {Clinicians and software developers need to understand how proposed machine learning (ML) models could improve patient care. No single metric captures all  the desirable properties of a model, which is why several metrics are typically  reported to summarize a model's performance. Unfortunately, these measures are  not easily understandable by many clinicians. Moreover, comparison of models  across studies in an objective manner is challenging, and no tool exists to  compare models using the same performance metrics. This paper looks at previous  ML studies done in gastroenterology, provides an explanation of what different  metrics mean in the context of binary classification in the presented studies,  and gives a thorough explanation of how different metrics should be interpreted.  We also release an open source web-based tool that may be used to aid in  calculating the most relevant metrics presented in this paper so that other  researchers and clinicians may easily incorporate them into their research.},
	language = {eng},
	number = {1},
	journal = {Scientific reports},
	author = {Hicks, Steven A. and Strümke, Inga and Thambawita, Vajira and Hammou, Malek and Riegler, Michael A. and Halvorsen, Pål and Parasa, Sravanthi},
	month = apr,
	year = {2022},
	pmid = {35395867},
	pmcid = {PMC8993826},
	note = {Place: England},
	keywords = {*Artificial Intelligence, *Benchmarking, Humans, Machine Learning, Software},
	pages = {5979},
}

@article{li_hyperband_2016,
	title = {Hyperband: {A} {Novel} {Bandit}-{Based} {Approach} to {Hyperparameter} {Optimization}},
	doi = {10.48550/arXiv.1603.06560},
	journal = {arXiv e-prints},
	author = {Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
	month = mar,
	year = {2016},
	note = {\_eprint: 1603.06560},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:1603.06560},
}

@article{akiba_optuna_2019,
	title = {Optuna: {A} {Next}-generation {Hyperparameter} {Optimization} {Framework}},
	doi = {10.48550/arXiv.1907.10902},
	journal = {arXiv e-prints},
	author = {Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
	month = jul,
	year = {2019},
	note = {\_eprint: 1907.10902},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:1907.10902},
}

@article{liu_predicting_2017,
	title = {Predicting {Organ} {Toxicity} {Using} in {Vitro} {Bioactivity} {Data} and {Chemical} {Structure}.},
	volume = {30},
	issn = {1520-5010 0893-228X},
	doi = {10.1021/acs.chemrestox.7b00084},
	abstract = {Animal testing alone cannot practically evaluate the health hazard posed by tens of thousands of environmental chemicals. Computational approaches making use of  high-throughput experimental data may provide more efficient means to predict  chemical toxicity. Here, we use a supervised machine learning strategy to  systematically investigate the relative importance of study type, machine  learning algorithm, and type of descriptor on predicting in vivo repeat-dose  toxicity at the organ-level. A total of 985 compounds were represented using  chemical structural descriptors, ToxPrint chemotype descriptors, and bioactivity  descriptors from ToxCast in vitro high-throughput screening assays. Using  ToxRefDB, a total of 35 target organ outcomes were identified that contained at  least 100 chemicals (50 positive and 50 negative). Supervised machine learning  was performed using Naïve Bayes, k-nearest neighbor, random forest,  classification and regression trees, and support vector classification  approaches. Model performance was assessed based on F1 scores using 5-fold  cross-validation with balanced bootstrap replicates. Fixed effects modeling  showed the variance in F1 scores was explained mostly by target organ outcome,  followed by descriptor type, machine learning algorithm, and interactions between  these three factors. A combination of bioactivity and chemical structure or  chemotype descriptors were the most predictive. Model performance improved with  more chemicals (up to a maximum of 24\%), and these gains were correlated (ρ =  0.92) with the number of chemicals. Overall, the results demonstrate that a  combination of bioactivity and chemical descriptors can accurately predict a  range of target organ toxicity outcomes in repeat-dose studies, but specific  experimental and methodologic improvements may increase predictivity.},
	language = {eng},
	number = {11},
	journal = {Chemical research in toxicology},
	author = {Liu, Jie and Patlewicz, Grace and Williams, Antony J. and Thomas, Russell S. and Shah, Imran},
	month = nov,
	year = {2017},
	pmid = {28768096},
	pmcid = {PMC6172960},
	note = {Place: United States},
	keywords = {*Machine Learning, Animals, Databases, Factual, Environmental Pollutants/chemistry/*toxicity, Humans, Models, Biological, Quantitative Structure-Activity Relationship, Toxicity Tests/*methods},
	pages = {2046--2059},
}

@inproceedings{brodersen_balanced_2010,
	title = {The {Balanced} {Accuracy} and {Its} {Posterior} {Distribution}},
	isbn = {1-4244-7542-2},
	abstract = {Evaluating the performance of a classification algorithm critically requires a measure of the degree to which unseen examples have been identified with their correct class labels. In practice, generalizability is frequently estimated by averaging the accuracies obtained on individual cross-validation folds. This procedure, however, is problematic in two ways. First, it does not allow for the derivation of meaningful confidence intervals. Second, it leads to an optimistic estimate when a biased classifier is tested on an imbalanced dataset. We show that both problems can be overcome by replacing the conventional point estimate of accuracy by an estimate of the posterior distribution of the balanced accuracy.},
	language = {eng},
	booktitle = {2010 20th {International} {Conference} on {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Brodersen, Kay H and Ong, Cheng Soon and Stephan, Klaas E and Buhmann, Joachim M},
	year = {2010},
	note = {ISSN: 1051-4651},
	keywords = {Approximation algorithms, Bias, Machine learning, Training},
	pages = {3121--3124},
}

@article{lobo_auc_2008,
	title = {{AUC}: a misleading measure of the performance of predictive distribution models},
	volume = {17},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1466-8238.2007.00358.x},
	doi = {https://doi.org/10.1111/j.1466-8238.2007.00358.x},
	abstract = {ABSTRACT The area under the receiver operating characteristic (ROC) curve, known as the AUC, is currently considered to be the standard method to assess the accuracy of predictive distribution models. It avoids the supposed subjectivity in the threshold selection process, when continuous probability derived scores are converted to a binary presence–absence variable, by summarizing overall model performance over all possible thresholds. In this manuscript we review some of the features of this measure and bring into question its reliability as a comparative measure of accuracy between model results. We do not recommend using AUC for five reasons: (1) it ignores the predicted probability values and the goodness-of-fit of the model; (2) it summarises the test performance over regions of the ROC space in which one would rarely operate; (3) it weights omission and commission errors equally; (4) it does not give information about the spatial distribution of model errors; and, most importantly, (5) the total extent to which models are carried out highly influences the rate of well-predicted absences and the AUC scores.},
	number = {2},
	journal = {Global Ecology and Biogeography},
	author = {Lobo, Jorge M. and Jiménez-Valverde, Alberto and Real, Raimundo},
	year = {2008},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1466-8238.2007.00358.x},
	keywords = {AUC, ROC curve, distribution models, ecological statistics, goodness-of-fit, model accuracy},
	pages = {145--151},
}

@article{hendrycks_gaussian_2016,
	title = {Gaussian {Error} {Linear} {Units} ({GELUs})},
	doi = {10.48550/arXiv.1606.08415},
	journal = {arXiv e-prints},
	author = {Hendrycks, Dan and Gimpel, Kevin},
	month = jun,
	year = {2016},
	note = {\_eprint: 1606.08415},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:1606.08415},
}

@article{loshchilov_decoupled_2017,
	title = {Decoupled {Weight} {Decay} {Regularization}},
	doi = {10.48550/arXiv.1711.05101},
	journal = {arXiv e-prints},
	author = {Loshchilov, Ilya and Hutter, Frank},
	month = nov,
	year = {2017},
	note = {\_eprint: 1711.05101},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Optimization and Control},
	pages = {arXiv:1711.05101},
}

@article{kingma_adam_2014,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	doi = {10.48550/arXiv.1412.6980},
	journal = {arXiv e-prints},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = dec,
	year = {2014},
	note = {\_eprint: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:1412.6980},
}

@article{al-hammuri_vision_2023,
	title = {Vision transformer architecture and applications in digital health: a tutorial and survey},
	volume = {6},
	issn = {2524-4442},
	url = {https://doi.org/10.1186/s42492-023-00140-9},
	doi = {10.1186/s42492-023-00140-9},
	abstract = {The vision transformer (ViT) is a state-of-the-art architecture for image recognition tasks that plays an important role in digital health applications. Medical images account for 90\% of the data in digital medicine applications. This article discusses the core foundations of the ViT architecture and its digital health applications. These applications include image segmentation, classification, detection, prediction, reconstruction, synthesis, and telehealth such as report generation and security. This article also presents a roadmap for implementing the ViT in digital health systems and discusses its limitations and challenges.},
	number = {1},
	journal = {Visual Computing for Industry, Biomedicine, and Art},
	author = {Al-hammuri, Khalid and Gebali, Fayez and Kanan, Awos and Chelvan, Ilamparithi Thirumarai},
	month = jul,
	year = {2023},
	pages = {14},
}

@article{kong_machine_2023,
	title = {Machine {Learning} {Techniques} {Applied} to the {Study} of {Drug} {Transporters}},
	volume = {28},
	copyright = {COPYRIGHT 2023 MDPI AG},
	issn = {1420-3049},
	abstract = {With the advancement of computer technology, machine learning-based artificial intelligence technology has been increasingly integrated and applied in the fields of medicine, biology, and pharmacy, thereby facilitating their development. Transporters have important roles in influencing drug resistance, drug–drug interactions, and tissue-specific drug targeting. The investigation of drug transporter substrates and inhibitors is a crucial aspect of pharmaceutical development. However, long duration and high expenses pose significant challenges in the investigation of drug transporters. In this review, we discuss the present situation and challenges encountered in applying machine learning techniques to investigate drug transporters. The transporters involved include ABC transporters (P-gp, BCRP, MRPs, and BSEP) and SLC transporters (OAT, OATP, OCT, MATE1,2-K, and NET). The aim is to offer a point of reference for and assistance with the progression of drug transporter research, as well as the advancement of more efficient computer technology. Machine learning methods are valuable and attractive for helping with the study of drug transporter substrates and inhibitors, but continuous efforts are still needed to develop more accurate and reliable predictive models and to apply them in the screening process of drug development to improve efficiency and success rates.},
	language = {eng},
	number = {16},
	journal = {Molecules (Basel, Switzerland)},
	author = {Kong, Xiaorui and Lin, Kexin and Wu, Gaolei and Tao, Xufeng and Zhai, Xiaohan and Lv, Linlin and Dong, Deshi and Zhu, Yanna and Yang, Shilei},
	year = {2023},
	note = {Place: Basel
Publisher: MDPI AG},
	keywords = {Algorithms, Artificial intelligence, Bioavailability, Cost control, Decision trees, Drug interactions, Drug resistance, Ligands, Liver, Machine learning, Metabolism, Metabolites, Pharmacokinetics, Proteins, Review, Toxicology},
	pages = {5936--},
}

@article{votano_three_2004,
	title = {Three new consensus {QSAR} models for the prediction of {Ames} genotoxicity},
	volume = {19},
	copyright = {2004 INIST-CNRS},
	issn = {0267-8357},
	abstract = {Three QSAR methods, artificial neural net (ANN), k-nearest neighbors (kNN), and Decision Forest (DF), were applied to 3363 diverse compounds tested for their Ames genotoxicity. The ratio of mutagens to non-mutagens was 60/40 for this dataset. This group of compounds includes {\textgreater}300 therapeutic drugs. All models were developed using the same initial set of 148 topological indices: molecular connectivity χ indices and electrotopological state indices (atom-type, bond-type and group-type E-state), as well as binary indicators. While previous studies have found logP to be a determining factor in genotoxicity, it was not found to be important by any modeling method employed in this study. The three models yielded an average training/test concordance value of 88\%, with a low percentage of false positives and false negatives. External validation testing on 400 compounds not used for QSAR model development gave an average concordance of 82\%. This value increased to 92\% upon removal of less reliable outcomes, as determined by a reliability criterion used within each model. The ANN model showed the best performance in predicting drug compounds, yielding 97\% concordance (34/35 drugs) after the removal of less reliable predictions. The appreciable commonality found among the top 10 ranked descriptors from each model is of particular interest because of the diversity in the learning algorithms and descriptor selection techniques employed in this study. Forty percent of the most important descriptors in any one model are found in one or two other models. Fourteen of the most important descriptors relate directly to known toxicophores involved in potent genotoxic responses in Salmonella typhimurium. A comparison of the validation results with those of MULTICASE and DEREK indicated that the new models presented in this work perform substantially better than the former models in predicting genotoxicity of therapeutic drugs. Substantially higher specificity was achieved with these new models as compared with MULTICASE or DEREK with comparable sensitivities among all models.},
	language = {eng},
	number = {5},
	journal = {Mutagenesis},
	author = {Votano, Joseph R. and Parham, Marc and Hall, Lowell H. and Kier, Lemont B. and Oloff, Scott and Tropsha, Alexander and Xie, Qian and Tong, Weida},
	year = {2004},
	note = {Place: Oxford
Publisher: Oxford University Press},
	keywords = {Algorithms, Chemical models, DNA damage, Drugs, Mathematical models, Molecular genetics, Mutagens, Neural networks (Computer science), Sensitivity and Specificity, Software},
	pages = {365--377},
}

@article{xu_silico_2012,
	title = {In silico {Prediction} of {Chemical} {Ames} {Mutagenicity}},
	volume = {52},
	copyright = {Copyright © 2012 American Chemical Society},
	issn = {1549-9596},
	abstract = {Mutagenicity is one of the most important end points of toxicity. Due to high cost and laboriousness in experimental tests, it is necessary to develop robust in silico methods to predict chemical mutagenicity. In this paper, a comprehensive database containing 7617 diverse compounds, including 4252 mutagens and 3365 nonmutagens, was constructed. On the basis of this data set, high predictive models were then built using five machine learning methods, namely support vector machine (SVM), C4.5 decision tree (C4.5 DT), artificial neural network (ANN), k-nearest neighbors (kNN), and naïve Bayes (NB), along with five fingerprints, namely CDK fingerprint (FP), Estate fingerprint (Estate), MACCS keys (MACCS), PubChem fingerprint (PubChem), and Substructure fingerprint (SubFP). Performances were measured by cross validation and an external test set containing 831 diverse chemicals. Information gain and substructure analysis were used to interpret the models. The accuracies of fivefold cross validation were from 0.808 to 0.841 for top five models. The range of accuracy for the external validation set was from 0.904 to 0.980, which outperformed that of Toxtree. Three models (PubChem-kNN, MACCS-kNN, and PubChem-SVM) showed high and reliable predictive accuracy for the mutagens and nonmutagens and, hence, could be used in prediction of chemical Ames mutagenicity.},
	language = {eng},
	number = {11},
	journal = {Journal of chemical information and modeling},
	author = {Xu, Congying and Cheng, Feixiong and Chen, Lei and Du, Zheng and Li, Weihua and Liu, Guixia and Lee, Philip W and Tang, Yun},
	year = {2012},
	note = {Place: Washington, DC
Publisher: American Chemical Society},
	keywords = {Animals, Artificial intelligence, Bayes Theorem, Chemical, Chemicals, Computer simulation, Databases, Decision trees, Human beings, Medical sciences, Mutagenesis, Neural networks (Computer science), Predictive Value of Tests, Reproducibility of Results, Software, Support vector machines, Toxicology},
	pages = {2840--2847},
}

@article{han_fda_2023,
	title = {{FDA} {Modernization} {Act} 2.0 allows for alternatives to animal testing.},
	volume = {47},
	copyright = {© 2023 International Center for Artificial Organ and Transplantation (ICAOT) and Wiley Periodicals LLC.},
	issn = {1525-1594 0160-564X},
	doi = {10.1111/aor.14503},
	abstract = {On December 29, 2022, President Biden signed into law the FDA Modernization Act 2.0. The bill essentially refutes the Federal Food, Drug, and Cosmetics Act of  1938, which mandated animal testing for every new drug development protocol.  While for the past century, the mandate was intended to ensure certain quality  and safety standards for drugs and medical devices, recent advancements in  science have begun to offer increasingly viable alternatives to animal testing.  For certain areas such as organ replacement therapies, non-animal testing may not  prove to be an adequate alternative in the foreseeable future.},
	language = {eng},
	number = {3},
	journal = {Artificial organs},
	author = {Han, Jason J.},
	month = mar,
	year = {2023},
	pmid = {36762462},
	note = {Place: United States},
	keywords = {*Animal Testing Alternatives, Animals, United States, United States Food and Drug Administration},
	pages = {449--450},
}

@misc{krizhevsky_imagenet_2017,
	title = {{ImageNet} classification with deep convolutional neural networks},
	copyright = {Copyright Association for Computing Machinery Jun 2017},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
	language = {eng},
	publisher = {ACM},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey},
	year = {2017},
	note = {ISSN: 0001-0782
Issue: 6
Pages: 84-90
Place: New York
Publication Title: Communications of the ACM
Volume: 60},
	keywords = {Competition, Errors, Mathematical models, Neurons, Training},
}

@article{kearnes_molecular_2016,
	title = {Molecular graph convolutions: moving beyond fingerprints},
	volume = {30},
	doi = {10.1007/s10822-016-9938-8},
	number = {8},
	journal = {Journal of Computer-Aided Molecular Design},
	author = {Kearnes, Steven and McCloskey, Kevin and Berndl, Marc and Pande, Vijay and Riley, Patrick},
	month = aug,
	year = {2016},
	note = {\_eprint: 1603.00856},
	keywords = {Artificial neural networks, Computer Science - Machine Learning, Deep learning, Machine learning, Molecular descriptors, Statistics - Machine Learning, Virtual screening},
	pages = {595--608},
}

@article{hartenfeller_enabling_2011,
	title = {Enabling future drug discovery by de novo design},
	volume = {1},
	issn = {1759-0876},
	doi = {10.1002/wcms.49},
	abstract = {Computer‐assisted drug design is evolving as a source of innovation for drug discovery. In particular, de novo design approaches are being increasingly applied to find novel drug‐like compounds, molecular scaffolds, and bioisosteric replacements for established or unwanted fragments. Although some of the early software tools had a certain tendency to generate compounds of limited chemical attraction, modern de novo design algorithms put a strong emphasis on the synthesizability and drug‐likeness of machine‐generated compounds. We give an overview of the various methodologies for virtual compound construction, evaluation, and optimization in machina, and how they can support medicinal chemistry projects in the early phase of drug discovery. © 2011 John Wiley \& Sons, Ltd. WIREs Comput Mol Sci 2011 1 742–759 DOI: 10.1002/wcms.49
This article is categorized under:
Computer and Information Science {\textgreater} Chemoinformatics},
	number = {5},
	journal = {Wiley interdisciplinary reviews. Computational molecular science},
	author = {Hartenfeller, Markus and Schneider, Gisbert},
	year = {2011},
	note = {Place: Hoboken, USA
Publisher: John Wiley \& Sons, Inc},
	pages = {742--759},
}

@article{kumar_deep_2021,
	title = {A deep neural network–based approach for prediction of mutagenicity of compounds},
	volume = {28},
	issn = {1614-7499},
	url = {https://doi.org/10.1007/s11356-021-14028-9},
	doi = {10.1007/s11356-021-14028-9},
	abstract = {We are exposed to various chemical compounds present in the environment, cosmetics, and drugs almost every day. Mutagenicity is a valuable property that plays a significant role in establishing a chemical compound’s safety. Exposure and handling of mutagenic chemicals in the environment pose a high health risk; therefore, identification and screening of these chemicals are essential. Considering the time constraints and the pressure to avoid laboratory animals’ use, the shift to alternative methodologies that can establish a rapid and cost-effective detection without undue over-conservation seems critical. In this regard, computational detection and identification of the mutagens in environmental samples like drugs, pesticides, dyes, reagents, wastewater, cosmetics, and other substances is vital. From the last two decades, there have been numerous efforts to develop the prediction models for mutagenicity, and by far, machine learning methods have demonstrated some noteworthy performance and reliability. However, the accuracy of such prediction models has always been one of the major concerns for the researchers working in this area. The mutagenicity prediction models were developed using deep neural network (DNN), support vector machine, k-nearest neighbor, and random forest. The developed classifiers were based on 3039 compounds and validated on 1014 compounds; each of them encoded with 1597 molecular feature vectors. DNN-based prediction model yielded highest prediction accuracy of 92.95\% and 83.81\% with the training and test data, respectively. The area under the receiver’s operating curve and precision-recall curve values were found to be 0.894 and 0.838, respectively. The DNN-based classifier not only fits the data with better performance as compared to traditional machine learning algorithms, viz., support vector machine, k-nearest neighbor, and random forest (with and without feature reduction) but also yields better performance metrics. In current work, we propose a DNN-based model to predict mutagenicity of compounds.},
	number = {34},
	journal = {Environmental Science and Pollution Research},
	author = {Kumar, Rajnish and Khan, Farhat Ullah and Sharma, Anju and Siddiqui, Mohammed Haris and Aziz, Izzatdin BA and Kamal, Mohammad Amjad and Ashraf, Ghulam Md and Alghamdi, Badrah S. and Uddin, Md. Sahab},
	month = sep,
	year = {2021},
	pages = {47641--47650},
}

@article{kamber_comparison_2009,
	title = {Comparison of the {Ames} {II} and traditional {Ames} test responses with respect to mutagenicity, strain specificities, need for metabolism and correlation with rodent carcinogenicity},
	volume = {24},
	issn = {0267-8357},
	url = {https://doi.org/10.1093/mutage/gep017},
	doi = {10.1093/mutage/gep017},
	abstract = {The Ames II Salmonella mutagenicity assay procedure was used to test 71 chemicals, and the results were compared with those from the traditional Ames Salmonella test using the NTP database as the reference. All Ames II tests were performed using a fluctuation procedure in microplate format, using TAMix for the detection of base pair substitutions and TA98 to detect frameshift mutations. There was 84\% agreement between the two procedures in identifying mutagens and non-mutagens, which is equivalent to the intra- and interlaboratory reproducibility of 87\% for the traditional test. The two tests also performed similarly in their predictions of rodent carcinogenicity.},
	number = {4},
	journal = {Mutagenesis},
	author = {Kamber, Markus and Flückiger-Isler, Sini and Engelhardt, Günter and Jaeckh, Rudolf and Zeiger, Errol},
	month = may,
	year = {2009},
	note = {\_eprint: https://academic.oup.com/mutage/article-pdf/24/4/359/3787533/gep017.pdf},
	pages = {359--366},
}

@article{yang_deep_2024,
	title = {Deep {Learning} {Algorithm} {Based} on {Molecular} {Fingerprint} for {Prediction} of {Drug}‐{Induced} {Liver} {Injury}},
	volume = {502},
	issn = {0300-483X},
	url = {https://www.sciencedirect.com/science/article/pii/S0300483X24000179},
	doi = {10.1016/j.tox.2024.153736},
	abstract = {Drug-induced liver injury (DILI) is one the rare adverse drug reaction (ADR) and multifactorial endpoints. Current preclinical animal models struggle to anticipate it, and in silico methods have emerged as a way with significant potential for doing so. In this study, a high-quality dataset of 1573 compounds was assembled. The 48 classification models, which depended on six different molecular fingerprints, were built via deep neural network (DNN) and seven machine learning algorithms. Comparing the results of the DNN and machine learning models, the optional performing model was found as the one developed based on the DNN with ECFP\_6 as input, which achieved the area under the receiver operating characteristic curve (AUC) of 0.713, balanced accuracy (BA) of 0.680, and F1 of 0.753. In addition, we used the SHapley Additive exPlanations (SHAP) algorithm to interpret the models, identified the crucial structural fragments related to DILI risk, and selected the top ten substructures with the highest contribution rankings to serve as warning indicators for subsequent drug hepatotoxicity screening studies. The study demonstrates that the DNN models developed based on molecular fingerprints can be a trustworthy and efficient tool for determining the risk of DILI during the pre-development of novel medications.},
	journal = {Toxicology},
	author = {Yang, Qiong and Zhang, Shuwei and Li, Yan},
	month = feb,
	year = {2024},
	keywords = {Deep neural network, Drug-induced liver injury, Machine learning, Molecular fingerprints, Shapley additive explanation},
	pages = {153736},
}

@inproceedings{subramanian_zeroth_2023,
	title = {Zeroth order {GreedyLR}: {An} adaptive learning rate scheduler for deep neural network training},
	url = {https://www.amazon.science/publications/zeroth-order-greedylr-an-adaptive-learning-rate-scheduler-for-deep-neural-network-training},
	booktitle = {{PRML} 2023},
	author = {Subramanian, Shreyas and Ganapathiraman, Vignesh},
	year = {2023},
}

@book{francois_fleuret_little_2023,
	title = {Little {Book} of {Deep} {Learning}},
	copyright = {Creative Commons BY-NC-SA 4.0 International License},
	url = {https://fleuret.org/public/lbdl.pdf},
	author = {{François Fleuret}},
	month = sep,
	year = {2023},
}

@article{he_realformer_2020,
	title = {{RealFormer}: {Transformer} {Likes} {Residual} {Attention}},
	doi = {10.48550/arXiv.2012.11747},
	journal = {arXiv e-prints},
	author = {He, Ruining and Ravula, Anirudh and Kanagal, Bhargav and Ainslie, Joshua},
	month = dec,
	year = {2020},
	note = {\_eprint: 2012.11747},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:2012.11747},
}

@article{dao_flashattention-2_2023,
	title = {{FlashAttention}-2: {Faster} {Attention} with {Better} {Parallelism} and {Work} {Partitioning}},
	doi = {10.48550/arXiv.2307.08691},
	journal = {arXiv e-prints},
	author = {Dao, Tri},
	month = jul,
	year = {2023},
	note = {\_eprint: 2307.08691},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:2307.08691},
}

@misc{aicis_guide_2022,
	title = {Guide to categorising your chemical importation and manufacture - {Step} 4.4 {Work} out your human health hazard characteristics},
	url = {https://www.industrialchemicals.gov.au/guide-categorising-your-chemical-importation-and-manufacture/step-4-work-out-your-introductions-risk-human-health/step-44-work-out-your-human-health-hazard-characteristics},
	language = {English},
	publisher = {AICIS},
	author = {{AICIS}},
	year = {2022},
}

@article{honma_improvement_2019,
	title = {Improvement of quantitative structure–activity relationship ({QSAR}) tools for predicting {Ames} mutagenicity: outcomes of the {Ames}/{QSAR} {International} {Challenge} {Project}},
	volume = {34},
	issn = {0267-8357},
	doi = {10.1093/mutage/gey031},
	abstract = {Abstract
The International Conference on Harmonization (ICH) M7 guideline allows the use of in silico approaches for predicting Ames mutagenicity for the initial assessment of impurities in pharmaceuticals. This is the first international guideline that addresses the use of quantitative structure–activity relationship (QSAR) models in lieu of actual toxicological studies for human health assessment. Therefore, QSAR models for Ames mutagenicity now require higher predictive power for identifying mutagenic chemicals. To increase the predictive power of QSAR models, larger experimental datasets from reliable sources are required. The Division of Genetics and Mutagenesis, National Institute of Health Sciences (DGM/NIHS) of Japan recently established a unique proprietary Ames mutagenicity database containing 12140 new chemicals that have not been previously used for developing QSAR models. The DGM/NIHS provided this Ames database to QSAR vendors to validate and improve their QSAR tools. The Ames/QSAR International Challenge Project was initiated in 2014 with 12 QSAR vendors testing 17 QSAR tools against these compounds in three phases. We now present the final results. All tools were considerably improved by participation in this project. Most tools achieved {\textgreater}50\% sensitivity (positive prediction among all Ames positives) and predictive power (accuracy) was as high as 80\%, almost equivalent to the inter-laboratory reproducibility of Ames tests. To further increase the predictive power of QSAR tools, accumulation of additional Ames test data is required as well as re-evaluation of some previous Ames test results. Indeed, some Ames-positive or Ames-negative chemicals may have previously been incorrectly classified because of methodological weakness, resulting in false-positive or false-negative predictions by QSAR tools. These incorrect data hamper prediction and are a source of noise in the development of QSAR models. It is thus essential to establish a large benchmark database consisting only of well-validated Ames test results to build more accurate QSAR models.},
	number = {1},
	journal = {Mutagenesis},
	author = {Honma, Masamitsu and Kitazawa, Airi and Cayley, Alex and Williams, Richard V and Barber, Chris and Hanser, Thierry and Saiakhov, Roustem and Chakravarti, Suman and Myatt, Glenn J and Cross, Kevin P and Benfenati, Emilio and Raitano, Giuseppa and Mekenyan, Ovanes and Petkov, Petko and Bossa, Cecilia and Benigni, Romualdo and Battistelli, Chiara Laura and Giuliani, Alessandro and Tcheremenskaia, Olga and DeMeo, Christine and Norinder, Ulf and Koga, Hiromi and Jose, Ciloy and Jeliazkova, Nina and Kochev, Nikolay and Paskaleva, Vesselina and Yang, Chihae and Daga, Pankaj R and Clark, Robert D and Rathman, James},
	year = {2019},
	note = {Place: UK
Publisher: Oxford University Press},
	keywords = {Computer simulation, Databases, Factual, Human beings, Japan, Mutagenicity testing},
	pages = {3--16},
}

@article{ames_improved_1973,
	title = {An improved bacterial test system for the detection and classification of mutagens and carcinogens.},
	volume = {70},
	issn = {0027-8424 1091-6490},
	doi = {10.1073/pnas.70.3.782},
	abstract = {We previously described a set of four strains of Salmonella typhimurium designed for detecting the various types of mutagens, and showed their utility in  detecting a wide variety of carcinogens as mutagens. The lipopolysaccharide that  normally coats these bacteria is a barrier to penetration of mutagens to the cell  membrane. The set of tester strains has been improved by adding a mutation (rfa:  deep rough) that results in a deficient lipopolysaccharide. The techniques for  using these strains for detecting mutagens are presented and the tests are shown  to be extremely sensitive and convenient. The specificity of frameshift  mutagenesis is clarified. As adjuncts to the test with the four strains, we  describe a test that compares mutagenic killing in deep rough strains with and  without DNA excision repair, and a test using forward mutagenesis in a deep rough  strain lacking excision repair.},
	language = {eng},
	number = {3},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Ames, B. N. and Lee, F. D. and Durston, W. E.},
	month = mar,
	year = {1973},
	pmid = {4577135},
	pmcid = {PMC433358},
	note = {Place: United States},
	keywords = {Acridines/pharmacology, Biological Assay, Carcinogens/*pharmacology, Ethidium/pharmacology, Fluorenes/pharmacology, Gentian Violet/pharmacology, Lipopolysaccharides/biosynthesis, Mechlorethamine/pharmacology, Mitomycins/pharmacology, Mutagens/*pharmacology, Mutation/drug effects, Nitroso Compounds/pharmacology, Nitrosoguanidines/pharmacology, Quinacrine/pharmacology, Quinolines/pharmacology, Salmonella typhimurium/*drug effects/metabolism},
	pages = {782--786},
}

@misc{noutahi_datamol_2023,
	title = {Datamol},
	url = {https://doi.org/10.5281/zenodo.8373019},
	publisher = {Zenodo},
	author = {Noutahi, Emmanuel and Wognum, Cas and Mary, Hadrien and Hounwanou, Honoré and Kovary, Kyle M. and Gilmour, Desmond and {thibaultvarin-r} and Burns, Jackson and St-Laurent, Julien and {t} and {DomInvivo} and Maheshkar, Saurav and {rbyrne-momatx}},
	month = sep,
	year = {2023},
	doi = {10.5281/zenodo.8373019},
}

@article{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	doi = {10.48550/arXiv.2005.14165},
	journal = {arXiv e-prints},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	month = may,
	year = {2020},
	note = {\_eprint: 2005.14165},
	keywords = {Computer Science - Computation and Language},
	pages = {arXiv:2005.14165},
}

@article{devlin_bert_2018,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	doi = {10.48550/arXiv.1810.04805},
	journal = {arXiv e-prints},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = oct,
	year = {2018},
	note = {\_eprint: 1810.04805},
	keywords = {Computer Science - Computation and Language},
	pages = {arXiv:1810.04805},
}

@article{dijkstra_note_1959,
	title = {A note on two problems in connexion with graphs},
	volume = {1},
	number = {1},
	journal = {Numerische mathematik},
	author = {Dijkstra, Edsger W},
	year = {1959},
	note = {Publisher: Springer},
	pages = {269--271},
}

@article{floyd_algorithm_1962,
	title = {Algorithm 97: {Shortest} path},
	volume = {5},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/367766.368168},
	doi = {10.1145/367766.368168},
	number = {6},
	journal = {Commun. ACM},
	author = {Floyd, Robert W.},
	month = jun,
	year = {1962},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	pages = {345},
}

@article{fey_fast_2019,
	title = {Fast {Graph} {Representation} {Learning} with {PyTorch} {Geometric}},
	url = {https://ui.adsabs.harvard.edu/abs/2019arXiv190302428F},
	doi = {10.48550/arXiv.1903.02428},
	abstract = {We introduce PyTorch Geometric, a library for deep learning on irregularly structured input data such as graphs, point clouds and manifolds, built upon PyTorch. In addition to general graph data structures and processing methods, it contains a variety of recently published methods from the domains of relational learning and 3D data processing. PyTorch Geometric achieves high data throughput by leveraging sparse GPU acceleration, by providing dedicated CUDA kernels and by introducing efficient mini-batch handling for input examples of different size. In this work, we present the library in detail and perform a comprehensive comparative study of the implemented methods in homogeneous evaluation scenarios.},
	journal = {arXiv e-prints},
	author = {Fey, Matthias and Lenssen, Jan Eric},
	month = mar,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:1903.02428},
}

@article{paszke_pytorch_2019,
	title = {{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}},
	url = {https://ui.adsabs.harvard.edu/abs/2019arXiv191201703P},
	doi = {10.48550/arXiv.1912.01703},
	abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
	journal = {arXiv e-prints},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	month = dec,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Computer Science - Mathematical Software, Statistics - Machine Learning},
	pages = {arXiv:1912.01703},
}

@article{he_delving_2015,
	title = {Delving {Deep} into {Rectifiers}: {Surpassing} {Human}-{Level} {Performance} on {ImageNet} {Classification}},
	url = {https://ui.adsabs.harvard.edu/abs/2015arXiv150201852H},
	doi = {10.48550/arXiv.1502.01852},
	abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit (PReLU) that generalizes the traditional rectified unit. PReLU improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our PReLU networks (PReLU-nets), we achieve 4.94\% top-5 test error on the ImageNet 2012 classification dataset. This is a 26\% relative improvement over the ILSVRC 2014 winner (GoogLeNet, 6.66\%). To our knowledge, our result is the first to surpass human-level performance (5.1\%, Russakovsky et al.) on this visual recognition challenge.},
	journal = {arXiv e-prints},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = feb,
	year = {2015},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	pages = {arXiv:1502.01852},
}

@phdthesis{raymond_lui_optimising_2018,
	title = {Optimising quantitative structure–mutagenicity models using novel cheminformatic techniques},
	school = {University of Sydney},
	author = {Raymond Lui},
	month = oct,
	year = {2018},
}

@article{thuy_hoang_survey_2024,
	title = {A {Survey} on {Structure}-{Preserving} {Graph} {Transformers}},
	doi = {10.48550/arXiv.2401.16176},
	abstract = {The transformer architecture has shown remarkable success in various domains, such as natural language processing and computer vision. When it comes to graph learning, transformers are required not only to capture the interactions between pairs of nodes but also to preserve graph structures connoting the underlying relations and proximity between them, showing the expressive power to capture different graph structures. Accordingly, various structure-preserving graph transformers have been proposed and widely used for various tasks, such as graph-level tasks in bioinformatics and chemoinformatics. However, strategies related to graph structure preservation have not been well organized and systematized in the literature. In this paper, we provide a comprehensive overview of structure-preserving graph transformers and generalize these methods from the perspective of their design objective. First, we divide strategies into four main groups: node feature modulation, context node sampling, graph rewriting, and transformer architecture improvements. We then further divide the strategies according to the coverage and goals of graph structure preservation. Furthermore, we also discuss challenges and future directions for graph transformer models to preserve the graph structure and understand the nature of graphs.},
	author = {Thuy Hoang, Van and Lee, O.-Joun},
	month = jan,
	year = {2024},
	keywords = {Computer Science - Artificial, Computer Science - Machine Learning, Intelligence},
	pages = {arXiv:2401.16176},
}

@article{wu_geodili_2023,
	title = {{GeoDILI}: {A} {Robust} and {Interpretable} {Model} for {Drug}-{Induced} {Liver} {Injury} {Prediction} {Using} {Graph} {Neural} {Network}-{Based} {Molecular} {Geometric} {Representation}},
	issn = {0893-228X},
	doi = {10.1021/acs.chemrestox.3c00199},
	journal = {Chemical research in toxicology},
	author = {Wu, Wenxuan and Qian, Jiayu and Liang, Changjie and Yang, Jingya and Ge, Guangbo and Zhou, Qingping and Guan, Xiaoqing},
	year = {2023},
}

@article{paykan_heyrati_bioact-het_2023,
	title = {{BioAct}-{Het}: {A} {Heterogeneous} {Siamese} {Neural} {Network} for {Bioactivity} {Prediction} {Using} {Novel} {Bioactivity} {Representation}},
	volume = {8},
	doi = {10.1021/acsomega.3c05778},
	number = {47},
	journal = {ACS omega},
	author = {Paykan Heyrati, Mehdi and Ghorbanali, Zahra and Akbari, Mohammad and Pishgahi, Ghasem and Zare-Mirakabad, Fatemeh},
	month = nov,
	year = {2023},
	pages = {44757--44772},
}

@article{lui_mechanistic_2023,
	title = {Mechanistic {Task} {Groupings} {Enhance} {Multitask} {Deep} {Learning} of {Strain}-{Specific} {Ames} {Mutagenicity}},
	volume = {36},
	issn = {0893-228X},
	doi = {10.1021/acs.chemrestox.2c00385},
	abstract = {The Ames test is a gold standard mutagenicity assay that utilizes various Salmonella typhimurium strains with and without S9 fraction to provide insights into the mechanisms by which a chemical can mutate DNA. Multitask deep learning is an ideal framework for developing QSAR models with multiple end points, such as the Ames test, as the joint training of multiple predictive tasks may synergistically improve the prediction accuracy of each task. This work investigated how toxicology domain knowledge can be used to handcraft task groupings that better guide the training of multitask neural networks compared to a naïve ungrouped multitask neural network developed on a complete set of tasks. Sixteen S. typhimurium ± S9 strain tasks were used to generate groupings based on mutagenic and metabolic mechanisms that were reflected in correlation data analyses. Both grouped and ungrouped multitask neural networks predicted the 16 strain tasks with a higher balanced accuracy compared with single task controls, with grouped multitask neural networks consistently featuring incremental increases in predictivity over the ungrouped approach. We conclude that the main variable driving these performance improvements is the general multitask effect with mechanistic task groupings acting as an enhancement step to further concentrate synergistic training signals united by a common biological mechanism. This approach enables incorporation of toxicology domain knowledge into multitask QSAR model development allowing for more transparent and accurate Ames mutagenicity prediction.},
	number = {8},
	journal = {Chemical research in toxicology},
	author = {Lui, Raymond and Guan, Davy and Matthews, Slade},
	year = {2023},
	pages = {1248--1254},
}

@article{shermukhamedov_structure_2023,
	title = {Structure to {Property}: {Chemical} {Element} {Embeddings} and a {Deep} {Learning} {Approach} for {Accurate} {Prediction} of {Chemical} {Properties}},
	doi = {10.48550/arXiv.2309.09355},
	abstract = {The application of machine learning (ML) techniques in computational chemistry has led to significant advances in predicting molecular properties, accelerating drug discovery, and material design. ML models can extract hidden patterns and relationships from complex and large datasets, allowing for the prediction of various chemical properties with high accuracy. The use of such methods has enabled the discovery of molecules and materials that were previously difficult to identify. This paper introduces a new ML model based on deep learning techniques, such as a multilayer encoder and decoder architecture, for classification tasks. We demonstrate the opportunities offered by our approach by applying it to various types of input data, including organic and inorganic compounds. In particular, we developed and tested the model using the Matbench and Moleculenet benchmarks, which include crystal properties and drug design-related benchmarks. We also conduct a comprehensive analysis of vector representations of chemical compounds, shedding light on the underlying patterns in molecular data. The models used in this work exhibit a high degree of predictive power, underscoring the progress that can be made with refined machine learning when applied to molecular and material datasets. For instance, on the Tox21 dataset, we achieved an average accuracy of 96\%, surpassing the previous best result by 10\%. Our code is publicly available at https://github.com/dmamur/elembert.},
	author = {Shermukhamedov, Shokirbek and Mamurjonova, Dilorom and Probst, Michael},
	month = sep,
	year = {2023},
	keywords = {Clusters, Computer Science - Machine Learning, Condensed Matter - Materials Science, Physics - Atomic and Molecular, Physics - Chemical Physics, Quantitative Biology - Quantitative Methods},
	pages = {arXiv:2309.09355},
}

@article{liu_ring_2023,
	title = {Ring {Attention} with {Blockwise} {Transformers} for {Near}-{Infinite} {Context}},
	doi = {10.48550/arXiv.2310.01889},
	abstract = {Transformers have emerged as the architecture of choice for many state-of-the-art AI models, showcasing exceptional performance across a wide range of AI applications. However, the memory demands imposed by Transformers limit their ability to handle long sequences, thereby posing challenges in utilizing videos, actions, and other long-form sequences and modalities in complex environments. We present a novel approach, Ring Attention with Blockwise Transformers (Ring Attention), which leverages blockwise computation of self-attention and feedforward to distribute long sequences across multiple devices while fully overlapping the communication of key-value blocks with the computation of blockwise attention. Our approach enables training and inference of sequences that are up to device count times longer than those achievable by prior memory-efficient Transformers, without resorting to approximations or incurring additional communication and computation overheads. Extensive experiments on language modeling and reinforcement learning tasks demonstrate the effectiveness of our approach in allowing millions of tokens context size and improving performance.},
	author = {Liu, Hao and Zaharia, Matei and Abbeel, Pieter},
	month = oct,
	year = {2023},
	keywords = {Computer Science - Computation and Language},
	pages = {arXiv:2310.01889},
}

@article{gao_transfoxmol_2023,
	title = {{TransFoxMol}: predicting molecular property with focused attention},
	volume = {24},
	issn = {1477-4054},
	doi = {10.1093/bib/bbad306},
	abstract = {Predicting the biological properties of molecules is crucial in computer-aided drug development, yet it’s often impeded by data scarcity and imbalance in many practical applications. Existing approaches are based on self-supervised learning or 3D data and using an increasing number of parameters to improve performance. These approaches may not take full advantage of established chemical knowledge and could inadvertently introduce noise into the respective model. In this study, we introduce a more elegant transformer-based framework with focused attention for molecular representation (TransFoxMol) to improve the understanding of artificial intelligence (AI) of molecular structure property relationships. TransFoxMol incorporates a multi-scale 2D molecular environment into a graph neural network + Transformer module and uses prior chemical maps to obtain a more focused attention landscape compared to that obtained using existing approaches. Experimental results show that TransFoxMol achieves state-of-the-art performance on MoleculeNet benchmarks and surpasses the performance of baselines that use self-supervised learning or geometry-enhanced strategies on small-scale datasets. Subsequent analyses indicate that TransFoxMol’s predictions are highly interpretable and the clever use of chemical knowledge enables AI to perceive molecules in a simple but rational way, enhancing performance.},
	number = {5},
	journal = {Briefings in Bioinformatics},
	author = {Gao, Jian and Shen, Zheyuan and Xie, Yufeng and Lu, Jialiang and Lu, Yang and Chen, Sikang and Bian, Qingyu and Guo, Yue and Shen, Liteng and Wu, Jian and Zhou, Binbin and Hou, Tingjun and He, Qiaojun and Che, Jinxin and Dong, Xiaowu},
	year = {2023},
}

@article{furuhama_evaluation_2023,
	title = {Evaluation of {QSAR} models for predicting mutagenicity: outcome of the {Second} {Ames}/{QSAR} international challenge project},
	volume = {34},
	issn = {1062-936X},
	doi = {10.1080/1062936X.2023.2284902},
	abstract = {Quantitative structure−activity relationship (QSAR) models are powerful in silico tools for predicting the mutagenicity of unstable compounds, impurities and metabolites that are difficult to examine using the Ames test. Ideally, Ames/QSAR models for regulatory use should demonstrate high sensitivity, low false-negative rate and wide coverage of chemical space. To promote superior model development, the Division of Genetics and Mutagenesis, National Institute of Health Sciences, Japan (DGM/NIHS), conducted the Second Ames/QSAR International Challenge Project (2020–2022) as a successor to the First Project (2014–2017), with 21 teams from 11 countries participating. The DGM/NIHS provided a curated training dataset of approximately 12,000 chemicals and a trial dataset of approximately 1,600 chemicals, and each participating team predicted the Ames mutagenicity of each trial chemical using various Ames/QSAR models. The DGM/NIHS then provided the Ames test results for trial chemicals to assist in model improvement. Although overall model performance on the Second Project was not superior to that on the First, models from the eight teams participating in both projects achieved higher sensitivity than models from teams participating in only the Second Project. Thus, these evaluations have facilitated the development of QSAR models.},
	number = {12},
	journal = {SAR and QSAR in environmental research},
	author = {Furuhama, A. and Kitazawa, A. and Yao, J. and Matos dos Santos, C. E. and Rathman, J. and Yang, C. and Ribeiro, J. V. and Cross, K. and Myatt, G. and Raitano, G. and Benfenati, E. and Jeliazkova, N. and Saiakhov, R. and Chakravarti, S. and Foster, R. S. and Bossa, C. and Battistelli, C. Laura and Benigni, R. and Sawada, T. and Wasada, H. and Hashimoto, T. and Wu, M. and Barzilay, R. and Daga, P. R. and Clark, R. D. and Mestres, J. and Montero, A. and Gregori-Puigjané, E. and Petkov, P. and Ivanova, H. and Mekenyan, O. and Matthews, S. and Guan, D. and Spicer, J. and Lui, R. and Uesawa, Y. and Kurosaki, K. and Matsuzaka, Y. and Sasaki, S. and Cronin, M. T. D. and Belfield, S. J. and Firman, J. W. and Spînu, N. and Qiu, M. and Keca, J. M. and Gini, G. and Li, T. and Tong, W. and Hong, H. and Liu, Z. and Igarashi, Y. and Yamada, H. and Sugiyama, K. I. and Honma, M.},
	year = {2023},
	keywords = {Ames test, Chemicals, Datasets, Genetics, Impurities, Metabolites, Mutagenesis, Mutagenicity, Sensitivity, Structure-activity relationships, Teams},
	pages = {983--1001},
}

@article{feeney_multiple_2023,
	title = {Multiple {Instance} {Learning} {Improves} {Ames} {Mutagenicity} {Prediction} for {Problematic} {Molecular} {Species}},
	volume = {36},
	issn = {0893-228X},
	doi = {10.1021/acs.chemrestox.2c00372},
	abstract = {The prediction of Ames mutagenicity continues to be a concern in both regulatory and pharmacological toxicology. Traditional quantitative structure–activity relationship (QSAR) models of mutagenicity make predictions based on molecular descriptors calculated on a chemical data set used in their training. However, it is known that molecules such as aromatic amines can be non-mutagenic themselves but metabolically activated by S9 rodent liver enzyme in Ames tests forming molecules such as iminoquinones or amine substituents that better stabilize mutagenic nitrenium ions in known pathways of mutagenicity. Modern in silico modeling methods can implicitly model these metabolites through consideration of the structural elements relevant to their formation but do not include explicit modeling of these metabolites’ potential activity. These metabolites do not have a known individual mutagenicity label and, in their current state, cannot be fitted into a traditional QSAR model. Multiple instance learning (MIL) however can be applied to a group of metabolites and their parent under a single mutagenicity label. Here we trained MIL models on Ames data, first with an aromatic amines data set (n = 457), a class known to require metabolic activation, and subsequently on a larger data set (n = 6505) incorporating multiple molecular species. MIL was shown to be able to predict Ames mutagenicity with performance in line with previously established models (balanced accuracy = 0.778), suggesting its potential utility in Ames prediction applications. Furthermore, the MIL model predicted well on identified hard-to-predict molecule groups relative to the models in which these molecule groups were identified. These results are presumably due to the increased consideration of the metabolic contribution to the mutagenic outcome. Further exploration of MIL as a supplement to existing models could aid in the prediction of chemicals where implicit modeling of metabolites cannot fully grasp their characteristics. This paper demonstrates the potential of an MIL approach to modeling Ames tests with S9 and is particularly relevant to metabolically activated xenobiotic mutagens.},
	number = {8},
	journal = {Chemical research in toxicology},
	author = {Feeney, Samuel V. and Lui, Raymond and Guan, Davy and Matthews, Slade},
	year = {2023},
	pages = {1227--1237},
}

@article{duval_hitchhikers_2023,
	title = {A {Hitchhiker}'s {Guide} to {Geometric} {GNNs} for {3D} {Atomic} {Systems}},
	doi = {10.48550/arXiv.2312.07511},
	abstract = {Recent advances in computational modelling of atomic systems, spanning molecules, proteins, and materials, represent them as geometric graphs with atoms embedded as nodes in 3D Euclidean space. In these graphs, the geometric attributes transform according to the inherent physical symmetries of 3D atomic systems, including rotations and translations in Euclidean space, as well as node permutations. In recent years, Geometric Graph Neural Networks have emerged as the preferred machine learning architecture powering applications ranging from protein structure prediction to molecular simulations and material generation. Their specificity lies in the inductive biases they leverage -- such as physical symmetries and chemical properties -- to learn informative representations of these geometric graphs. In this opinionated paper, we provide a comprehensive and self-contained overview of the field of Geometric GNNs for 3D atomic systems. We cover fundamental background material and introduce a pedagogical taxonomy of Geometric GNN architectures:(1) invariant networks, (2) equivariant networks in Cartesian basis, (3) equivariant networks in spherical basis, and (4) unconstrained networks. Additionally, we outline key datasets and application areas and suggest future research directions. The objective of this work is to present a structured perspective on the field, making it accessible to newcomers and aiding practitioners in gaining an intuition for its mathematical abstractions.},
	author = {Duval, Alexandre and Mathis, Simon V. and Joshi, Chaitanya K. and Schmidt, Victor and Miret, Santiago and Malliaros, Fragkiskos D. and Cohen, Taco and Lio, Pietro and Bengio, Yoshua and Bronstein, Michael},
	month = dec,
	year = {2023},
	keywords = {Computer Science - Artificial, Computer Science - Machine Learning, Intelligence, Machine Learning, Quantitative Biology - Quantitative Methods, Statistics -},
	pages = {arXiv:2312.07511},
}

@article{abdulhameed_using_2023,
	title = {Using a {Graph} {Convolutional} {Neural} {Network} {Model} to {Identify} {Bile} {Salt} {Export} {Pump} {Inhibitors}},
	volume = {8},
	issn = {2470-1343},
	doi = {10.1021/acsomega.3c01583},
	abstract = {The bile salt export pump (BSEP) is a key transporter involved in the efflux of bile salts from hepatocytes to bile canaliculi. Inhibition of BSEP leads to the accumulation of bile salts within the hepatocytes, leading to possible cholestasis and drug-induced liver injury. Screening for and identification of chemicals that inhibit this transporter aid in understanding the safety liabilities of these chemicals. Moreover, computational approaches to identify BSEP inhibitors provide an alternative to the more resource-intensive, gold standard experimental approaches. Here, we used publicly available data to develop predictive machine learning models for the identification of potential BSEP inhibitors. Specifically, we analyzed the utility of a graph convolutional neural network (GCNN)-based approach in combination with multitask learning to identify BSEP inhibitors. Our analyses showed that the developed GCNN model performed better than the variable-nearest neighbor and Bayesian machine learning approaches, with a cross-validation receiver operating characteristic area under the curve of 0.86. In addition, we compared GCNN-based single-task and multitask models and evaluated their utility in addressing data limitation challenges commonly observed in bioactivity modeling. We found that multitask models performed better than single-task models and can be utilized to identify active molecules for targets with limited data availability. Overall, our developed multitask GCNN-based BSEP model provides a useful tool for prioritizing hits during early drug discovery and in risk assessment of chemicals.},
	number = {24},
	journal = {ACS omega},
	author = {AbdulHameed, Mohamed Diwan M. and Liu, Ruifeng and Wallqvist, Anders},
	year = {2023},
	pages = {21853--21861},
}

@book{boldini_effectiveness_2023,
	title = {Effectiveness of molecular fingerprints for exploring the chemical space of natural products},
	author = {Boldini, Davide and Ballabio, Davide and Consonni, Viviana and Todeschini, Roberto and Grisoni, Francesca and Sieber, Stephan},
	year = {2023},
}

@misc{australian_competition__consumer_commission_recalls_2024,
	title = {Recalls},
	author = {Australian Competition \& Consumer Commission},
	month = jan,
	year = {2024},
}

@article{shi_benchmarking_2022,
	title = {Benchmarking {Graphormer} on {Large}-{Scale} {Molecular} {Modeling} {Datasets}},
	doi = {10.48550/arXiv.2203.04810},
	abstract = {This technical note describes the recent updates of Graphormer, including architecture design modifications, and the adaption to 3D molecular dynamics simulation. With these simple modifications, Graphormer could attain better results on large-scale molecular modeling datasets than the vanilla one, and the performance gain could be consistently obtained on 2D and 3D molecular graph modeling tasks. In addition, we show that with a global receptive field and an adaptive aggregation strategy, Graphormer is more powerful than classic message-passing-based GNNs. Empirically, Graphormer could achieve much less MAE than the originally reported results on the PCQM4M quantum chemistry dataset used in KDD Cup 2021. In the meanwhile, it greatly outperforms the competitors in the recent Open Catalyst Challenge, which is a competition track on NeurIPS 2021 workshop, and aims to model the catalyst-adsorbate reaction system with advanced AI models. All codes could be found at https://github.com/Microsoft/Graphormer.},
	author = {Shi, Yu and Zheng, Shuxin and Ke, Guolin and Shen, Yifei and You, Jiacheng and He, Jiyan and Luo, Shengjie and Liu, Chang and He, Di and Liu, Tie-Yan},
	month = mar,
	year = {2022},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:2203.04810},
}

@article{fang_geometry-enhanced_2022,
	title = {Geometry-enhanced molecular representation learning for property prediction},
	volume = {4},
	issn = {2522-5839},
	doi = {10.1038/s42256-021-00438-4},
	abstract = {Abstract Effective molecular representation learning is of great importance to facilitate molecular property prediction. Recent advances for molecular representation learning have shown great promise in applying graph neural networks to model molecules. Moreover, a few recent studies design self-supervised learning methods for molecular representation to address insufficient labelled molecules; however, these self-supervised frameworks treat the molecules as topological graphs without fully utilizing the molecular geometry information. The molecular geometry, also known as the three-dimensional spatial structure of a molecule, is critical for determining molecular properties. To this end, we propose a novel geometry-enhanced molecular representation learning method (GEM). The proposed GEM has a specially designed geometry-based graph neural network architecture as well as several dedicated geometry-level self-supervised learning strategies to learn the molecular geometry knowledge. We compare GEM with various state-of-the-art baselines on different benchmarks and show that it can considerably outperform them all, demonstrating the superiority of the proposed method.},
	number = {2},
	journal = {Nature machine intelligence},
	author = {Fang, Xiaomin and Liu, Lihang and Lei, Jieqiong and He, Donglong and Zhang, Shanzhuo and Zhou, Jingbo and Wang, Fan and Wu, Hua and Wang, Haifeng},
	year = {2022},
	keywords = {Chemical bonds, Computer architecture, Geometry, Graph neural networks, Graph representations, Graphical representations, Graphs, Learning, Molecular structure, Neural networks, Supervised learning, Teaching methods, Topology},
	pages = {127--134},
}

@article{jin_refined_2022,
	title = {Refined {Edge} {Usage} of {Graph} {Neural} {Networks} for {Edge} {Prediction}},
	issn = {2331-8422},
	doi = {10.48550/arxiv.2212.12970},
	abstract = {Graph Neural Networks (GNNs), originally proposed for node classification, have also motivated many recent works on edge prediction (a.k.a., link prediction). However, existing methods lack elaborate design regarding the distinctions between two tasks that have been frequently overlooked: (i) edges only constitute the topology in the node classification task but can be used as both the topology and the supervisions (i.e., labels) in the edge prediction task; (ii) the node classification makes prediction over each individual node, while the edge prediction is determinated by each pair of nodes. To this end, we propose a novel edge prediction paradigm named Edge-aware Message PassIng neuRal nEtworks (EMPIRE). Concretely, we first introduce an edge splitting technique to specify use of each edge where each edge is solely used as either the topology or the supervision (named as topology edge or supervision edge). We then develop a new message passing mechanism that generates the messages to source nodes (through topology edges) being aware of target nodes (through supervision edges). In order to emphasize the differences between pairs connected by supervision edges and pairs unconnected, we further weight the messages to highlight the relative ones that can reflect the differences. In addition, we design a novel negative node-pair sampling trick that efficiently samples 'hard' negative instances in the supervision instances, and can significantly improve the performance. Experimental results verify that the proposed method can significantly outperform existing state-of-the-art models regarding the edge prediction task on multiple homogeneous and heterogeneous graph datasets.},
	journal = {arXiv.org},
	author = {Jin, Jiarui and Wang, Yangkun and Zhang, Weinan and Gan, Quan and Song, Xiang and Yu, Yong and Zhang, Zheng and Wipf, David},
	year = {2022},
	keywords = {Classification, Graph neural networks, Message passing, Messages, Network topologies, Neural networks, Nodes, Supervision},
}

@article{bishnoi_enhancing_2022,
	title = {Enhancing the {Inductive} {Biases} of {Graph} {Neural} {ODE} for {Modeling} {Dynamical} {Systems}},
	issn = {2331-8422},
	doi = {10.48550/arxiv.2209.10740},
	abstract = {Neural networks with physics based inductive biases such as Lagrangian neural networks (LNN), and Hamiltonian neural networks (HNN) learn the dynamics of physical systems by encoding strong inductive biases. Alternatively, Neural ODEs with appropriate inductive biases have also been shown to give similar performances. However, these models, when applied to particle based systems, are transductive in nature and hence, do not generalize to large system sizes. In this paper, we present a graph based neural ODE, GNODE, to learn the time evolution of dynamical systems. Further, we carefully analyse the role of different inductive biases on the performance of GNODE. We show that, similar to LNN and HNN, encoding the constraints explicitly can significantly improve the training efficiency and performance of GNODE significantly. Our experiments also assess the value of additional inductive biases, such as Newtons third law, on the final performance of the model. We demonstrate that inducing these biases can enhance the performance of model by orders of magnitude in terms of both energy violation and rollout error. Interestingly, we observe that the GNODE trained with the most effective inductive biases, namely MCGNODE, outperforms the graph versions of LNN and HNN, namely, Lagrangian graph networks (LGN) and Hamiltonian graph networks (HGN) in terms of energy violation error by approx 4 orders of magnitude for a pendulum system, and approx 2 orders of magnitude for spring systems. These results suggest that competitive performances with energy conserving neural networks can be obtained for NODE based systems by inducing appropriate inductive biases.},
	journal = {arXiv.org},
	author = {Bishnoi, Suresh and Bhattoo, Ravinder and Sayan, Ranu and Krishnan, N. M. Anoop},
	year = {2022},
	keywords = {Dynamical systems, Neural networks},
}

@article{li_deepdili_2021,
	title = {{DeepDILI}: {Deep} {Learning}-{Powered} {Drug}-{Induced} {Liver} {Injury} {Prediction} {Using} {Model}-{Level} {Representation}},
	volume = {34},
	issn = {1520-5010 (Electronic) 0893-228X (Linking)},
	doi = {10.1021/acs.chemrestox.0c00374},
	abstract = {Drug-induced liver injury (DILI) is the most frequently reported single cause of safety-related withdrawal of marketed drugs. It is essential to identify drugs with DILI potential at the early stages of drug development. In this study, we describe a deep learning-powered DILI (DeepDILI) prediction model created by combining model-level representation generated by conventional machine learning (ML) algorithms with a deep learning framework based on Mold2 descriptors. We conducted a comprehensive evaluation of the proposed DeepDILI model performance by posing several critical questions: (1) Could the DILI potential of newly approved drugs be predicted by accumulated knowledge of early approved ones? (2) is model-level representation more informative than molecule-based representation for DILI prediction? and (3) could improved model explainability be established? For question 1, we developed the DeepDILI model using drugs approved before 1997 to predict the DILI potential of those approved thereafter. As a result, the DeepDILI model outperformed the five conventional ML algorithms and two state-of-the-art ensemble methods with a Matthews correlation coefficient (MCC) value of 0.331. For question 2, we demonstrated that the DeepDILI model's performance was significantly improved (i.e., a MCC improvement of 25.86\% in test set) compared with deep neural networks based on molecule-based representation. For question 3, we found 21 chemical descriptors that were enriched, suggesting a strong association with DILI outcome. Furthermore, we found that the DeepDILI model has more discrimination power to identify the DILI potential of drugs belonging to the World Health Organization therapeutic category of 'alimentary tract and metabolism'. Moreover, the DeepDILI model based on Mold2 descriptors outperformed the ones with Mol2vec and MACCS descriptors. Finally, the DeepDILI model was applied to the recent real-world problem of predicting any DILI concern for potential COVID-19 treatments from repositioning drug candidates. Altogether, this developed DeepDILI model could serve as a promising tool for screening for DILI risk of compounds in the preclinical setting, and the DeepDILI model is publicly available through https://github.com/TingLi2016/DeepDILI.},
	number = {2},
	journal = {Chem Res Toxicol},
	author = {Li, T. and Tong, W. and Roberts, R. and Liu, Z. and Thakkar, S.},
	month = feb,
	year = {2021},
	keywords = {*COVID-19 Drug Treatment, *Chemical and Drug Induced Liver Injury, *Deep Learning, *Drug Repositioning, *Models, Theoretical, *SARS-CoV-2},
	pages = {550--565},
}

@article{hung_qsar_2021,
	title = {{QSAR} modeling without descriptors using graph convolutional neural networks: the case of mutagenicity prediction},
	volume = {25},
	issn = {1381-1991},
	doi = {10.1007/s11030-021-10250-2},
	abstract = {Deep neural networks are effective in learning directly from low-level encoded data without the need of feature extraction. This paper shows how QSAR models can be constructed from 2D molecular graphs without computing chemical descriptors. Two graph convolutional neural network-based models are presented with and without a Bayesian estimation of the prediction uncertainty. The property under investigation is mutagenicity: Models developed here predict the output of the Ames test. These models take the SMILES representation of the molecules as input to produce molecular graphs in terms of adjacency matrices and subsequently use attention mechanisms to weight the role of their subgraphs in producing the output. The results positively compare with current state-of-the-art models. Furthermore, our proposed model interpretation can be enhanced by the automatic extraction of the substructures most important in driving the prediction, as well as by uncertainty estimations. Graphic abstract},
	number = {3},
	journal = {Molecular diversity},
	author = {Hung, Chiakang and Gini, Giuseppina},
	year = {2021},
	keywords = {Adjacency matrix, Algorithms, Artificial intelligence, Bayes Theorem, Bayes estimator, Biochemistry, Biomedical and Life Sciences, Computer science, Convolutional neural network, Deep Learning, Drug Discovery - methods, Feature extraction, Life Sciences, Models, Theoretical, Molecular Structure, Mutagenesis - drug effects, Mutagens - chemistry, Mutagens - pharmacology, Mutagens - toxicity, Neural Networks, Computer, Neural networks, Organic Chemistry, Original Article, Pattern recognition, Pharmacy, Polymer Sciences, Quantitative Structure-Activity Relationship, Representation (mathematics), Two-graph, chemical sciences, general chemistry, natural sciences},
	pages = {1283--1299},
}

@article{chengxuan_transformers_2021,
	title = {Do {Transformers} {Really} {Perform} {Bad} for {Graph} {Representation}?},
	issn = {2331-8422},
	doi = {10.48550/arxiv.2106.05234},
	abstract = {The Transformer architecture has become a dominant choice in many domains, such as natural language processing and computer vision. Yet, it has not achieved competitive performance on popular leaderboards of graph-level prediction compared to mainstream GNN variants. Therefore, it remains a mystery how Transformers could perform well for graph representation learning. In this paper, we solve this mystery by presenting Graphormer, which is built upon the standard Transformer architecture, and could attain excellent results on a broad range of graph representation learning tasks, especially on the recent OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the graph is the necessity of effectively encoding the structural information of a graph into the model. To this end, we propose several simple yet effective structural encoding methods to help Graphormer better model graph-structured data. Besides, we mathematically characterize the expressive power of Graphormer and exhibit that with our ways of encoding the structural information of graphs, many popular GNN variants could be covered as the special cases of Graphormer.},
	journal = {arXiv.org},
	author = {Chengxuan, Ying and Cai, Tianle and Luo, Shengjie and Zheng, Shuxin and Ke, Guolin and He, Di and Shen, Yanming and Tie-Yan, Liu},
	year = {2021},
	keywords = {Cognitive tasks, Computer vision, Graph representations, Graphical representations, Learning, Natural language processing, Transformers},
}

@article{zaheer_big_2020,
	title = {Big {Bird}: {Transformers} for {Longer} {Sequences}},
	doi = {10.48550/arXiv.2007.14062},
	abstract = {Transformers-based models, such as BERT, have been one of the most successful deep learning models for NLP. Unfortunately, one of their core limitations is the quadratic dependency (mainly in terms of memory) on the sequence length due to their full attention mechanism. To remedy this, we propose, BigBird, a sparse attention mechanism that reduces this quadratic dependency to linear. We show that BigBird is a universal approximator of sequence functions and is Turing complete, thereby preserving these properties of the quadratic, full attention model. Along the way, our theoretical analysis reveals some of the benefits of having \$O(1)\$ global tokens (such as CLS), that attend to the entire sequence as part of the sparse attention mechanism. The proposed sparse attention can handle sequences of length up to 8x of what was previously possible using similar hardware. As a consequence of the capability to handle longer context, BigBird drastically improves performance on various NLP tasks such as question answering and summarization. We also propose novel applications to genomics data.},
	author = {Zaheer, Manzil and Guruganesh, Guru and Dubey, Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and Ahmed, Amr},
	month = jul,
	year = {2020},
	keywords = {Computer Science - Computation, Computer Science - Machine Learning, Statistics - Machine Learning, and Language},
	pages = {arXiv:2007.14062},
}

@article{tinto-moliner_quantitative_2020,
	title = {Quantitative weight of evidence method for combining predictions of quantitative structure-activity relationship models},
	volume = {31},
	issn = {1062-936X},
	doi = {10.1080/1062936X.2020.1725116},
	abstract = {A method for combining statistical-based QSAR predictions of two or more binary classification models is presented. It was assumed that all models were independent. This facilitated the combination of positive and negative predictions using a quantitative weight of evidence (qWoE) procedure based on Bayesian statistics and the additivity of the logarithms of the likelihood ratios. Previous studies combined more than one prediction but used arbitrary strengths for positive and negative predictions. In our approach, the combined models were validated by determining the sensitivity and specificity values, which are performance metrics that are a point of departure for obtaining values that measure the weight of evidence of positive and negative predictions. The developed method was experimentally applied in the prediction of Ames mutagenicity. The method achieved a similar accuracy to that of the experimental Ames test for this endpoint when the overall prediction was determined using a combination of the individual predictions of more than one model. Calculating the qWoE value would reduce the requirement for expert knowledge and decrease the subjectivity of the prediction. This method could be applied to other endpoints such as developmental toxicity and skin sensitisation with binary classification models.},
	number = {4},
	journal = {SAR and QSAR in environmental research},
	author = {Tintó-Moliner, A. and Martin, M.},
	year = {2020},
	keywords = {Ames test, Ames mutagenicity, Bayesian analysis, Classification, ICH M7 guideline, Logarithms, Mathematical models, Mutagenicity, Performance measurement, Predictions, Quantitative weight of evidence (qWoE), Statistical analysis, Structure-activity relationships, Toxicity, Weight, combining binary classifiers, quantitative structure-activity relationship (QSAR)},
	pages = {261--279},
}

@misc{chemoinformatics_kode_alvadesc_2022,
	title = {{alvaDesc} 2.0},
	author = {Chemoinformatics Kode},
	year = {2022},
}

@article{wiercioch_dealing_2021,
	title = {Dealing with a data-limited regime: {Combining} transfer learning and transformer attention mechanism to increase aqueous solubility prediction performance},
	volume = {1},
	issn = {2667-3185},
	doi = {10.1016/j.ailsci.2021.100021},
	abstract = {[Display omitted] Aqueous solubility is a key chemical property that drives various processes in chemistry and biology. Its computational prediction is challenging, as evidenced by the fact that it has been a subject of considerable interest for several decades. Recent work has explored fingerprint-based, feature-based and graph-based representations with different machine learning and deep learning methodologies. In general, many traditional methods have been proposed, but they rely heavily on the quality of the rule-based, hand-crafted features. On the other hand, limitations in the quality of aqueous solubility data become a handicap when training deep models. In this study, we have developed a novel structure-aware method for the prediction of aqueous solubility by introducing a new deep network architecture and then employing a transfer learning approach. The model was proven to be competitive, obtaining an RMSE of 0.587 during both cross-validation and a test on an independent dataset. To be more precise, the method is evaluated on molecules downloaded from the Online Chemical Database and Modeling Environment (OCHEM). Beyond aqueous solubility prediction, the strategy presented in this work may be useful for modeling any kind of (chemical or biological) properties for which there is a limited amount of data available for model training.},
	journal = {Artificial intelligence in the life sciences},
	author = {Wiercioch, Magdalena and Kirchmair, Johannes},
	year = {2021},
	keywords = {Aqueous solubility, Cheminformatics, Deep Learning, Drug discovery, Regression, Transformer model},
	pages = {100021},
}

@article{ma_deep_2021,
	title = {Deep {Graph} {Learning} with {Property} {Augmentation} for {Predicting} {Drug}-{Induced} {Liver} {Injury}},
	volume = {34},
	issn = {0893-228X},
	doi = {10.1021/acs.chemrestox.0c00322},
	number = {2},
	journal = {Chemical research in toxicology},
	author = {Ma, Hehuan and An, Weizhi and Wang, Yuhong and Sun, Hongmao and Huang, Ruili and Huang, Junzhou},
	month = feb,
	year = {2021},
	pages = {495--506},
}

@article{guilian_luchini_fingerprints_2021,
	title = {Fingerprints: {Clashing} and {Clustering}},
	author = {Guilian Luchini},
	year = {2021},
}

@article{li_dgl-lifesci_2021,
	title = {{DGL}-{LifeSci}: {An} {Open}-{Source} {Toolkit} for {Deep} {Learning} on {Graphs} in {Life} {Science}},
	volume = {6},
	issn = {2470-1343},
	doi = {10.1021/acsomega.1c04017},
	abstract = {Graph neural networks (GNNs) constitute a class of deep learning methods for graph data. They have wide applications in chemistry and biology, such as molecular property prediction, reaction prediction, and drug–target interaction prediction. Despite the interest, GNN-based modeling is challenging as it requires graph data preprocessing and modeling in addition to programming and deep learning. Here, we present Deep Graph Library (DGL)-LifeSci, an open-source package for deep learning on graphs in life science. Deep Graph Library (DGL)-LifeSci is a python toolkit based on RDKit, PyTorch, and Deep Graph Library (DGL). DGL-LifeSci allows GNN-based modeling on custom datasets for molecular property prediction, reaction prediction, and molecule generation. With its command-line interfaces, users can perform modeling without any background in programming and deep learning. We test the command-line interfaces using standard benchmarks MoleculeNet, USPTO, and ZINC. Compared with previous implementations, DGL-LifeSci achieves a speed up by up to 6×. For modeling flexibility, DGL-LifeSci provides well-optimized modules for various stages of the modeling pipeline. In addition, DGL-LifeSci provides pretrained models for reproducing the test experiment results and applying models without training. The code is distributed under an Apache-2.0 License and is freely accessible at https://github.com/awslabs/dgl-lifesci .},
	number = {41},
	journal = {ACS omega},
	author = {Li, Mufei and Zhou, Jinjing and Hu, Jiajing and Fan, Wenxuan and Zhang, Yangkang and Gu, Yaxin and Karypis, George},
	year = {2021},
	pages = {27233--27238},
}

@article{gasteiger_gemnet_2021,
	title = {{GemNet}: {Universal} {Directional} {Graph} {Neural} {Networks} for {Molecules}},
	doi = {10.48550/arXiv.2106.08903},
	abstract = {Effectively predicting molecular interactions has the potential to accelerate molecular dynamics by multiple orders of magnitude and thus revolutionize chemical simulations. Graph neural networks (GNNs) have recently shown great successes for this task, overtaking classical methods based on fixed molecular kernels. However, they still appear very limited from a theoretical perspective, since regular GNNs cannot distinguish certain types of graphs. In this work we close this gap between theory and practice. We show that GNNs with directed edge embeddings and two-hop message passing are indeed universal approximators for predictions that are invariant to translation, and equivariant to permutation and rotation. We then leverage these insights and multiple structural improvements to propose the geometric message passing neural network (GemNet). We demonstrate the benefits of the proposed changes in multiple ablation studies. GemNet outperforms previous models on the COLL, MD17, and OC20 datasets by 34\%, 41\%, and 20\%, respectively, and performs especially well on the most challenging molecules. Our implementation is available online.},
	author = {Gasteiger, Johannes and Becker, Florian and Günnemann, Stephan},
	month = jun,
	year = {2021},
	keywords = {Computer Science - Machine Learning, Physics - Chemical Physics, Physics - Computational Physics, Statistics - Machine Learning},
	pages = {arXiv:2106.08903},
}

@phdthesis{samuel_feeney_metabolic_2021,
	type = {Honours},
	title = {Metabolic prediction in the modelling of aromatic amine {Ames} mutagenicity},
	school = {The University of Sydney},
	author = {Samuel Feeney},
	year = {2021},
}

@article{xiong_pushing_2020,
	title = {Pushing the {Boundaries} of {Molecular} {Representation} for {Drug} {Discovery} with the {Graph} {Attention} {Mechanism}},
	volume = {63},
	issn = {0022-2623},
	doi = {10.1021/acs.jmedchem.9b00959},
	number = {16},
	journal = {Journal of Medicinal Chemistry},
	author = {Xiong, Zhaoping and Wang, Dingyan and Liu, Xiaohong and Zhong, Feisheng and Wan, Xiaozhe and Li, Xutong and Li, Zhaojun and Luo, Xiaomin and Chen, Kaixian and Jiang, Hualiang and Zheng, Mingyue},
	month = aug,
	year = {2020},
	pages = {8749--8760},
}

@article{zhou_graph_2020,
	title = {Graph neural networks: {A} review of methods and applications},
	volume = {1},
	issn = {2666-6510},
	doi = {https://doi.org/10.1016/j.aiopen.2021.01.001},
	abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.},
	journal = {AI Open},
	author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
	month = jan,
	year = {2020},
	keywords = {Deep learning, Graph neural network},
	pages = {57--81},
}

@article{thakkar_drug-induced_2020,
	title = {Drug-induced liver injury severity and toxicity ({DILIst}): binary classification of 1279 drugs by human hepatotoxicity},
	volume = {25},
	issn = {1359-6446},
	doi = {https://doi.org/10.1016/j.drudis.2019.09.022},
	abstract = {Drug-induced liver injury (DILI) is of significant concern to drug development and regulatory review because of the limited success with existing preclinical models. For developing alternative methods, a large drug list is needed with known DILI severity and toxicity. We augmented the DILIrank data set [annotated using US Food and Drug Administration (FDA) drug labeling)] with four literature datasets (N {\textgreater}350 drugs) to generate the largest drug list with DILI classification, called DILIst (DILI severity and toxicity). DILIst comprises 1279 drugs, of which 768 were DILI positives (increase of 65\% from DILIrank), whereas 511 were DILI negatives (increase of 65\%). The investigation of DILI positive–negative distribution across various therapeutic categories revealed the most and least frequent DILI categories. Thus, we consider DILIst to be an invaluable resource for the community to improve DILI research.},
	number = {1},
	journal = {Drug Discovery Today},
	author = {Thakkar, Shraddha and Li, Ting and Liu, Zhichao and Wu, Leihong and Roberts, Ruth and Tong, Weida},
	month = jan,
	year = {2020},
	pages = {201--208},
}

@article{weaver_managing_2020,
	title = {Managing the challenge of drug-induced liver injury: a roadmap for the development and deployment of preclinical predictive models},
	volume = {19},
	issn = {1474-1784},
	doi = {10.1038/s41573-019-0048-x},
	abstract = {Drug-induced liver injury (DILI) is a patient-specific, temporal, multifactorial pathophysiological process that cannot yet be recapitulated in a single in vitro model. Current preclinical testing regimes for the detection of human DILI thus remain inadequate. A systematic and concerted research effort is required to address the deficiencies in current models and to present a defined approach towards the development of new or adapted model systems for DILI prediction. This Perspective defines the current status of available models and the mechanistic understanding of DILI, and proposes our vision of a roadmap for the development of predictive preclinical models of human DILI.},
	number = {2},
	journal = {Nature Reviews Drug Discovery},
	author = {Weaver, Richard J. and Blomme, Eric A. and Chadwick, Amy E. and Copple, Ian M. and Gerets, Helga H. J. and Goldring, Christopher E. and Guillouzo, Andre and Hewitt, Philip G. and Ingelman-Sundberg, Magnus and Jensen, Klaus Gjervig and Juhila, Satu and Klingmüller, Ursula and Labbe, Gilles and Liguori, Michael J. and Lovatt, Cerys A. and Morgan, Paul and Naisbitt, Dean J. and Pieters, Raymond H. H. and Snoeys, Jan and van de Water, Bob and Williams, Dominic P. and Park, B. Kevin},
	month = feb,
	year = {2020},
	pages = {131--148},
}

@article{lui_comparison_2020,
	title = {A comparison of molecular representations for lipophilicity quantitative structure–property relationships with results from the {SAMPL6} {logP} {Prediction} {Challenge}},
	volume = {34},
	issn = {0920-654X},
	doi = {10.1007/s10822-020-00279-0},
	abstract = {Effective representation of a molecule is required to develop useful quantitative structure–property relationships (QSPR) for accurate prediction of chemical properties. The octanol–water partition coefficient logP, a measure of lipophilicity, is an important property for pharmacological and toxicological endpoints used in the pharmaceutical and regulatory spheres. We compare physicochemical descriptors, structural keys, and circular fingerprints in their ability to effectively represent a chemical space and characterise molecular features to correlate with lipophilicity. Exploratory landscape continuity analyses revealed that whole-molecule physicochemical descriptors could map together compounds that were similar in both molecular features and logP, indicating higher potential for use in logP QSPRs compared to the substructural approach of structural keys and circular fingerprints. Indeed, logP QSPR models parameterised by physicochemical descriptors consistently performed with the lowest error. Our best performing model was a stochastic gradient descent-optimised multilinear regression with 1438 descriptors, returning an internal benchmark RMSE of 1.03 log units. This corroborates the well-established notion that lipophilicity is an additive, whole-molecule property. We externally tested the model by participating in the 2019 SAMPL6 logP Prediction Challenge and blindly predicting for 11 protein kinase inhibitor fragment-like molecules. Our model returned an RMSE of 0.49 log units, placing eighth overall and third in the empirical methods category (submission ID ‘hdpuj’). Permutation feature importance analyses revealed that physicochemical descriptors could characterise predictive molecular features highly relevant to the kinase inhibitor fragment-like molecules.},
	number = {5},
	journal = {Journal of computer-aided molecular design},
	author = {Lui, Raymond and Guan, Davy and Matthews, Slade},
	year = {2020},
	keywords = {Animal Anatomy, Chemical properties, Chemistry, Chemistry and Materials Science, Computer Applications in Chemistry, Empirical analysis, Fingerprints, Histology, Inhibitors, Kinases, Lipophilicity, Machine learning, Model testing, Molecular structure, Morphology, Permutations, Physical Chemistry, Physicochemical properties, Predictions, QSPR, Regression analysis, Representations, SAMPL6, logP},
	pages = {523--534},
}

@article{shi_molecular_2019,
	title = {Molecular image-based convolutional neural network for the prediction of {ADMET} properties},
	volume = {194},
	issn = {0169-7439},
	doi = {10.1016/j.chemolab.2019.103853},
	abstract = {Convolutional neural network (CNN), is one of the most representative architectures in deep learning and is widely adopted in many fields especially in image classification and object detection. In the last few years, CNN has been aroused more and more attentions in drug discovery domain. In this work, molecular 2-D image-based CNN method was used to establish prediction models of the ADMET properties, including CYP1A2 inhibitory potency, P-glycoprotein (P-gp) inhibitory activity, Blood-Brain Barrier (BBB) penetrating activity, and Ames mutagenicity. The results showed that the predictive power of the established CNN models is comparable to that of the available machine learning models based on manual structural description and feature selection. It can be inferred that CNN can extract efficiently the key image features related to the molecular ADMET properties and offer a useful tool for virtual screening and drug design researches. •The CNN method based on 2-D molecular image can efficiently extract key molecular features related to the ADMET properties.•The established CNN models achieved comparable prediction performances as the available traditional machine learning models.•The CNN method can provide a very promising way for automated virtual screening and drug design researches.},
	journal = {Chemometrics and intelligent laboratory systems},
	author = {Shi, Tingting and Yang, Yingwu and Huang, Shuheng and Chen, Linxin and Kuang, Zuyin and Heng, Yu and Mei, Hu},
	year = {2019},
	keywords = {ADMET, Artificial intelligence, Computer science, Contextual image classification, Convolutional neural network, Deep learning, Domain (software engineering), Feature selection, Image (mathematics), Molecular image, Object detection, Pattern recognition, Prediction, Virtual screening, analytical chemistry, chemical sciences, developmental biology, health sciences, medical and health sciences, natural sciences},
	pages = {103853},
}

@article{chan_measures_2018,
	title = {Measures of {BSEP} {Inhibition} {In} {Vitro} {Are} {Not} {Useful} {Predictors} of {DILI}},
	volume = {162},
	issn = {1096-6080 (Print) 1096-0929},
	doi = {10.1093/toxsci/kfx284},
	abstract = {Inhibition of the bile salt export pump (BSEP) by a drug has been implicated as a risk factor for a drug's potential to cause drug-induced liver injury (DILI) and is thought to be an important mechanism leading to DILI. For a wide variety of drugs a correlation has been observed between the potency of in vitro BSEP inhibition and its propensity to cause DILI in humans. These findings were interpreted to suggest that BSEP inhibition could be an important mechanism to help explain how some drugs initiate DILI. Because the Biopharmaceutics Drug Disposition Classification System (BDDCS) can be useful in characterizing and predicting some important transporter effects in terms of drug-drug interactions, we evaluated the information provided by BDDCS in order to understand the inhibition propensity of BSEP. Here we analyze the relationship between a compound's ability to inhibit BSEP function and cause liver injury in humans using a compilation of published DILI datasets that have screened for BSEP inhibitors, other hepatic transporters and other mechanism-based toxicity key events. Our results demonstrate that there is little support for in vitro BSEP inhibition being universally DILI predictive. Rather we show that most potent BSEP inhibitors are BDDCS class 2 drugs, which we have demonstrated previously is the BDDCS class most likely to be DILI related. Since BDDCS class is not related to any proposed DILI mechanistic hypotheses, we maintain that if measures of BSEP inhibition alone or together with inhibition of other transporters cannot be differentiated from class 2 assignment, there is no support for in vitro BSEP inhibition being DILI predictive.},
	language = {eng},
	number = {2},
	journal = {Toxicol Sci},
	author = {Chan, R. and Benet, L. Z.},
	month = apr,
	year = {2018},
	pmcid = {PMC5888978},
	keywords = {ATP Binding Cassette Transporter, Subfamily B, Member 11/*antagonists \&, Animals, Chemical and Drug Induced Liver Injury/*etiology/metabolism, Dose-Response Relationship, Drug, Drug Evaluation, Preclinical, Drug Labeling, Humans, Mitochondria, Liver/*drug effects, Models, Theoretical, Pharmaceutical Preparations/administration \& dosage/*classification, Predictive Value of Tests, inhibitors},
	pages = {499--508},
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	issn = {2331-8422},
	doi = {10.48550/arxiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	journal = {arXiv.org},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	year = {2017},
	keywords = {Artificial neural networks, Configuration management, Encoders-Decoders, Machine translation, Neural networks, Training, Transformers, Translations},
}

@article{siramshetty_withdrawn--resource_2016,
	title = {{WITHDRAWN}--a resource for withdrawn and discontinued drugs},
	volume = {44},
	issn = {1362-4962 (Electronic) 0305-1048 (Print) 0305-1048 (Linking)},
	doi = {10.1093/nar/gkv1192},
	abstract = {Post-marketing drug withdrawals can be associated with various events, ranging from safety issues such as reported deaths or severe side-effects, to a multitude of non-safety problems including lack of efficacy, manufacturing, regulatory or business issues. During the last century, the majority of drugs voluntarily withdrawn from the market or prohibited by regulatory agencies was reported to be related to adverse drug reactions. Understanding the underlying mechanisms of toxicity is of utmost importance for current and future drug discovery. Here, we present WITHDRAWN, a resource for withdrawn and discontinued drugs publicly accessible at http://cheminfo.charite.de/withdrawn. Today, the database comprises 578 withdrawn or discontinued drugs, their structures, important physico-chemical properties, protein targets and relevant signaling pathways. A special focus of the database lies on the drugs withdrawn due to adverse reactions and toxic effects. For approximately one half of the drugs in the database, safety issues were identified as the main reason for withdrawal. Withdrawal reasons were extracted from the literature and manually classified into toxicity types representing adverse effects on different organs. A special feature of the database is the presence of multiple search options which will allow systematic analyses of withdrawn drugs and their mechanisms of toxicity.},
	number = {D1},
	journal = {Nucleic Acids Res},
	author = {Siramshetty, V. B. and Nickel, J. and Omieczynski, C. and Gohlke, B. O. and Drwal, M. N. and Preissner, R.},
	month = jan,
	year = {2016},
	pmcid = {PMC4702851},
	keywords = {*Databases, Pharmaceutical, *Safety-Based Drug Withdrawals, Drug Recalls, Drug-Related Side Effects and Adverse Reactions, Humans, Internet, Pharmaceutical Preparations/chemistry, Polymorphism, Single Nucleotide, Proteins/drug effects, Signal Transduction/drug effects},
	pages = {D1080--6},
}

@article{altman_curses_2018,
	title = {The curse(s) of dimensionality},
	volume = {15},
	issn = {1548-7091},
	doi = {10.1038/s41592-018-0019-x},
	abstract = {There is such a thing as too much of a good thing.},
	number = {6},
	journal = {Nature methods},
	author = {Altman, Naomi and Krzywinski, Martin},
	year = {2018},
	keywords = {Big data, Clinical medicine, Computer science, Data Interpretation, Statistical, Data processing, Developmental biology, Experimental design, Gaussian distribution, Genomics, Information retrieval, Machine learning, Metabolites, Methodology, Methods, Numerical analysis, Parks, Sample Size, Scientists, Statistical methods, Statistics, Universities and colleges},
	pages = {399--400},
}

@inproceedings{velickovic_graph_2017,
	title = {Graph {Attention} {Networks}},
	isbn = {2331-8422},
	doi = {10.48550/arxiv.1710.10903},
	abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).},
	publisher = {Cornell University Library, arXiv.org},
	author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
	year = {2017},
	keywords = {Approximation, Graph neural networks, Neural networks, Nodes, Proteins},
}

@article{wen_learning_2016,
	title = {Learning {Structured} {Sparsity} in {Deep} {Neural} {Networks}},
	doi = {10.48550/arXiv.1608.03665},
	abstract = {High demand for computation resources severely hinders deployment of large-scale Deep Neural Networks (DNN) in resource constrained devices. In this work, we propose a Structured Sparsity Learning (SSL) method to regularize the structures (i.e., filters, channels, filter shapes, and layer depth) of DNNs. SSL can: (1) learn a compact structure from a bigger DNN to reduce computation cost; (2) obtain a hardware-friendly structured sparsity of DNN to efficiently accelerate the DNNs evaluation. Experimental results show that SSL achieves on average 5.1x and 3.1x speedups of convolutional layer computation of AlexNet against CPU and GPU, respectively, with off-the-shelf libraries. These speedups are about twice speedups of non-structured sparsity; (3) regularize the DNN structure to improve classification accuracy. The results show that for CIFAR-10, regularization on layer depth can reduce 20 layers of a Deep Residual Network (ResNet) to 18 layers while improve the accuracy from 91.25\% to 92.60\%, which is still slightly higher than that of original ResNet with 32 layers. For AlexNet, structure regularization by SSL also reduces the error by around {\textasciitilde}1\%. Open source code is in https://github.com/wenwei202/caffe/tree/scnn},
	author = {Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
	month = aug,
	year = {2016},
	keywords = {Computer, Computer Science - Neural and Evolutionary Computing, I.2.6, I.5.1, Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:1608.03665},
}

@article{onakpoya_post-marketing_2016,
	title = {Post-marketing withdrawal of 462 medicinal products because of adverse drug reactions: a systematic review of the world literature},
	volume = {14},
	issn = {1741-7015},
	doi = {10.1186/s12916-016-0553-2},
	abstract = {There have been no studies of the patterns of post-marketing withdrawals of medicinal products to which adverse reactions have been attributed. We identified medicinal products that were withdrawn because of adverse drug reactions, examined the evidence to support such withdrawals, and explored the pattern of withdrawals across countries. We searched PubMed, Google Scholar, the WHO's database of drugs, the websites of drug regulatory authorities, and textbooks. We included medicinal products withdrawn between 1950 and 2014 and assessed the levels of evidence used in making withdrawal decisions using the criteria of the Oxford Centre for Evidence Based Medicine. We identified 462 medicinal products that were withdrawn from the market between 1953 and 2013, the most common reason being hepatotoxicity. The supporting evidence in 72 \% of cases consisted of anecdotal reports. Only 43 (9.34 \%) drugs were withdrawn worldwide and 179 (39 \%) were withdrawn in one country only. Withdrawal was significantly less likely in Africa than in other continents (Europe, the Americas, Asia, and Australasia and Oceania). The median interval between the first reported adverse reaction and the year of first withdrawal was 6 years (IQR, 1-15) and the interval did not consistently shorten over time. There are discrepancies in the patterns of withdrawal of medicinal products from the market when adverse reactions are suspected, and withdrawals are inconsistent across countries. Greater co-ordination among drug regulatory authorities and increased transparency in reporting suspected adverse drug reactions would help improve current decision-making processes.},
	number = {10},
	journal = {BMC medicine},
	author = {Onakpoya, Igho J. and Heneghan, Carl J. and Aronson, Jeffrey K.},
	year = {2016},
	keywords = {Adverse Drug Reaction Reporting Systems - standards, Adverse Drug Reaction Reporting Systems - statistics \& numerical data, Adverse drug reaction, Africa - epidemiology, Americas - epidemiology, Analysis, Asia - epidemiology, Australasia - epidemiology, Clinical trials, Databases, Factual - statistics \& numerical data, Decision-making, Drug withdrawal, Drug-Related Side Effects and Adverse Reactions - epidemiology, Europe - epidemiology, Evidence-Based Medicine - statistics \& numerical data, Humans, Marketing, Oceania - epidemiology, Publications - statistics \& numerical data, Safety-Based Drug Withdrawals - statistics \& numerical data, Systematic review, Voluntary recall},
	pages = {10--11},
}

@article{seo_development_2020,
	title = {Development of {Natural} {Compound} {Molecular} {Fingerprint} ({NC}-{MFP}) with the {Dictionary} of {Natural} {Products} ({DNP}) for natural product-based drug development},
	volume = {12},
	issn = {1758-2946},
	doi = {10.1186/s13321-020-0410-3},
	abstract = {Computer-aided research on the relationship between molecular structures of natural compounds (NC) and their biological activities have been carried out extensively because the molecular structures of new drug candidates are usually analogous to or derived from the molecular structures of NC. In order to express the relationship physically realistically using a computer, it is essential to have a molecular descriptor set that can adequately represent the characteristics of the molecular structures belonging to the NC’s chemical space. Although several topological descriptors have been developed to describe the physical, chemical, and biological properties of organic molecules, especially synthetic compounds, and have been widely used for drug discovery researches, these descriptors have limitations in expressing NC-specific molecular structures. To overcome this, we developed a novel molecular fingerprint, called Natural Compound Molecular Fingerprints (NC-MFP), for explaining NC structures related to biological activities and for applying the same for the natural product (NP)-based drug development. NC-MFP was developed to reflect the structural characteristics of NCs and the commonly used NP classification system. NC-MFP is a scaffold-based molecular fingerprint method comprising scaffolds, scaffold-fragment connection points (SFCP), and fragments. The scaffolds of the NC-MFP have a hierarchical structure. In this study, we introduce 16 structural classes of NPs in the Dictionary of Natural Product database (DNP), and the hierarchical scaffolds of each class were calculated using the Bemis and Murko (BM) method. The scaffold library in NC-MFP comprises 676 scaffolds. To compare how well the NC-MFP represents the structural features of NCs compared to the molecular fingerprints that have been widely used for organic molecular representation, two kinds of binary classification tasks were performed. Task I is a binary classification of the NCs in commercially available library DB into a NC or synthetic compound. Task II is classifying whether NCs with inhibitory activity in seven biological target proteins are active or inactive. Two tasks were developed with some molecular fingerprints, including NC-MFP, using the 1-nearest neighbor (1-NN) method. The performance of task I showed that NC-MFP is a practical molecular fingerprint to classify NC structures from the data set compared with other molecular fingerprints. Performance of task II with NC-MFP outperformed compared with other molecular fingerprints, suggesting that the NC-MFP is useful to explain NC structures related to biological activities. In conclusion, NC-MFP is a robust molecular fingerprint in classifying NC structures and explaining the biological activities of NC structures. Therefore, we suggest NC-MFP as a potent molecular descriptor of the virtual screening of NC for natural product-based drug development.},
	number = {1},
	journal = {Journal of Cheminformatics},
	author = {Seo, Myungwon and Shin, Hyun Kil and Myung, Yoochan and Hwang, Sungbo and No, Kyoung Tai},
	month = jan,
	year = {2020},
	pages = {6},
}

@phdthesis{davy_guan_silico_2020,
	type = {Doctoral},
	title = {In silico {Methods} for {Predictive} {Toxicological} and {Pharmacological} {Modelling}},
	school = {The University of Sydney},
	author = {Davy Guan},
	year = {2020},
}

@phdthesis{guan_silico_2020,
	title = {In silico methods for predictive toxicological and pharmacological modelling},
	school = {University of Sydney},
	author = {Guan, Davy},
	year = {2020},
	keywords = {chemistry, computational, modelling, pharmacology, qsar, toxicology},
}

@article{wolf_huggingfaces_2019,
	title = {{HuggingFace}'s {Transformers}: {State}-of-the-art {Natural} {Language} {Processing}},
	doi = {10.48550/arXiv.1910.03771},
	abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. {\textbackslash}textit\{Transformers\} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. {\textbackslash}textit\{Transformers\} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at {\textbackslash}url\{https://github.com/huggingface/transformers\}.},
	author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
	month = oct,
	year = {2019},
	keywords = {Computer Science - Computation and Language},
	pages = {arXiv:1910.03771},
}

@article{dwivedi_generalization_2020,
	title = {A {Generalization} of {Transformer} {Networks} to {Graphs}},
	doi = {10.48550/arXiv.2012.09699},
	abstract = {We propose a generalization of transformer neural network architecture for arbitrary graphs. The original transformer was designed for Natural Language Processing (NLP), which operates on fully connected graphs representing all connections between the words in a sequence. Such architecture does not leverage the graph connectivity inductive bias, and can perform poorly when the graph topology is important and has not been encoded into the node features. We introduce a graph transformer with four new properties compared to the standard model. First, the attention mechanism is a function of the neighborhood connectivity for each node in the graph. Second, the positional encoding is represented by the Laplacian eigenvectors, which naturally generalize the sinusoidal positional encodings often used in NLP. Third, the layer normalization is replaced by a batch normalization layer, which provides faster training and better generalization performance. Finally, the architecture is extended to edge feature representation, which can be critical to tasks s.a. chemistry (bond type) or link prediction (entity relationship in knowledge graphs). Numerical experiments on a graph benchmark demonstrate the performance of the proposed graph transformer architecture. This work closes the gap between the original transformer, which was designed for the limited case of line graphs, and graph neural networks, that can work with arbitrary graphs. As our architecture is simple and generic, we believe it can be used as a black box for future applications that wish to consider transformer and graphs.},
	author = {Dwivedi, Vijay Prakash and Bresson, Xavier},
	month = dec,
	year = {2020},
	keywords = {Computer Science - Machine Learning},
	pages = {arXiv:2012.09699},
}

@article{capecchi_one_2020,
	title = {One molecular fingerprint to rule them all: drugs, biomolecules, and the metabolome},
	volume = {12},
	issn = {1758-2946},
	doi = {10.1186/s13321-020-00445-4},
	abstract = {Molecular fingerprints are essential cheminformatics tools for virtual screening and mapping chemical space. Among the different types of fingerprints, substructure fingerprints perform best for small molecules such as drugs, while atom-pair fingerprints are preferable for large molecules such as peptides. However, no available fingerprint achieves good performance on both classes of molecules.},
	number = {1},
	journal = {Journal of Cheminformatics},
	author = {Capecchi, Alice and Probst, Daniel and Reymond, Jean-Louis},
	month = jun,
	year = {2020},
	pages = {43},
}

@article{wang_deep_2019,
	title = {Deep {Graph} {Library}: {A} {Graph}-{Centric}, {Highly}-{Performant} {Package} for {Graph} {Neural} {Networks}},
	issn = {2331-8422},
	doi = {10.48550/arxiv.1909.01315},
	abstract = {Advancing research in the emerging field of deep graph learning requires new tools to support tensor computation over graphs. In this paper, we present the design principles and implementation of Deep Graph Library (DGL). DGL distills the computational patterns of GNNs into a few generalized sparse tensor operations suitable for extensive parallelization. By advocating graph as the central programming abstraction, DGL can perform optimizations transparently. By cautiously adopting a framework-neutral design, DGL allows users to easily port and leverage the existing components across multiple deep learning frameworks. Our evaluation shows that DGL significantly outperforms other popular GNN-oriented frameworks in both speed and memory consumption over a variety of benchmarks and has little overhead for small scale workloads.},
	journal = {arXiv.org},
	author = {Wang, Minjie and Zheng, Da and Ye, Zihao and Gan, Quan and Li, Mufei and Song, Xiang and Zhou, Jinjing and Ma, Chao and Yu, Lingfan and Yu, Gai and Xiao, Tianjun and He, Tong and Karypis, George and Li, Jinyang and Zhang, Zheng},
	year = {2019},
	keywords = {Feature extraction, Fuses, Graph neural networks, Graphs, Machine learning, Mutation, Tensors},
}

@article{hey_epidemiology_2019,
	title = {Epidemiology and outcomes of acute liver failure in {Australia}},
	volume = {11},
	issn = {1948-5182 (Print)},
	doi = {10.4254/wjh.v11.i7.586},
	abstract = {BACKGROUND: Acute liver failure (ALF) is a life-threatening syndrome with varying aetiologies requiring complex care and multidisciplinary management. Its changing incidence, aetiology and outcomes over the last 16 years in the Australian context remain uncertain. AIM: To describe the changing incidence, aetiology and outcomes of ALF in South Eastern Australia. METHODS: The database of the Victorian Liver Transplant Unit was interrogated to identify all cases of ALF in adults ({\textgreater} 16 years) in adults hospitalised between January 2002 and December 2017. Overall, 169 patients meeting criteria for ALF were identified. Demographics, aetiology of ALF, rates of transplantation and outcomes were collected for all patients. Transplant free survival and overall survival (OS) were assessed based on survival to discharge from hospital. Results were compared to data from a historical cohort from the same unit from 1988-2001. RESULTS: Paracetamol was the most common aetiology of acute liver failure, accounting for 50\% of cases, with an increased incidence compared with the historical cohort (P = 0.046). Viral hepatitis and non-paracetamol drug or toxin induced liver injury accounted for 15\% and 10\% of cases respectively. Transplant free survival (TFS) improved significantly compared to the historical cohort (52\% vs 38\%, P = 0.032). TFS was highest in paracetamol toxicity with spontaneous recovery in 72\% of cases compared to 31\% of non-paracetamol ALF (P {\textless} 0.001). Fifty-nine patients were waitlisted for emergency liver transplantation. Nine of these died while waiting for an organ to become available. Forty-two patients (25\%) underwent emergency liver transplantation with a 1, 3 and 5 year survival of 81\%, 78\% and 72\% respectively. CONCLUSION: Paracetamol toxicity is the most common aetiology of ALF in South-Eastern Australia with a rising incidence over 30 years. TFS has improved, however it remains low in non-paracetamol ALF.},
	language = {eng},
	number = {7},
	journal = {World J Hepatol},
	author = {Hey, P. and Hanrahan, T. P. and Sinclair, M. and Testro, A. G. and Angus, P. W. and Peterson, A. and Warrillow, S. and Bellomo, R. and Perini, M. V. and Starkey, G. and Jones, R. M. and Fink, M. and McClure, T. and Gow, P.},
	month = jul,
	year = {2019},
	pmcid = {PMC6669190},
	keywords = {Acute, Australia, Liver failure, Liver transplant, Paracetamol, Victoria},
	pages = {586--595},
}

@article{alperstein_all_2019,
	title = {All {SMILES} {Variational} {Autoencoder}},
	doi = {10.48550/arXiv.1905.13343},
	abstract = {Variational autoencoders (VAEs) defined over SMILES string and graph-based representations of molecules promise to improve the optimization of molecular properties, thereby revolutionizing the pharmaceuticals and materials industries. However, these VAEs are hindered by the non-unique nature of SMILES strings and the computational cost of graph convolutions. To efficiently pass messages along all paths through the molecular graph, we encode multiple SMILES strings of a single molecule using a set of stacked recurrent neural networks, pooling hidden representations of each atom between SMILES representations, and use attentional pooling to build a final fixed-length latent representation. By then decoding to a disjoint set of SMILES strings of the molecule, our All SMILES VAE learns an almost bijective mapping between molecules and latent representations near the high-probability-mass subspace of the prior. Our SMILES-derived but molecule-based latent representations significantly surpass the state-of-the-art in a variety of fully- and semi-supervised property regression and molecular property optimization tasks.},
	author = {Alperstein, Zaccary and Cherkasov, Artem and Rolfe, Jason Tyler},
	month = may,
	year = {2019},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {arXiv:1905.13343},
}

@article{fernandez_toxic_2018,
	title = {Toxic {Colors}: {The} {Use} of {Deep} {Learning} for {Predicting} {Toxicity} of {Compounds} {Merely} from {Their} {Graphic} {Images}},
	volume = {58},
	issn = {1549-9596},
	doi = {10.1021/acs.jcim.8b00338},
	abstract = {The majority of computational methods for predicting toxicity of chemicals are typically based on “nonmechanistic” cheminformatics solutions, relying on an arsenal of QSAR descriptors, often vaguely associated with chemical structures, and typically employing “black-box” mathematical algorithms. Nonetheless, such machine learning models, while having lower generalization capacity and interpretability, typically achieve a very high accuracy in predicting various toxicity endpoints, as unambiguously reflected by the results of the recent Tox21 competition. In the current study, we capitalize on the power of modern AI to predict Tox21 benchmark data using merely simple 2D drawings of chemicals, without employing any chemical descriptors. In particular, we have processed rather trivial 2D sketches of molecules with a supervised 2D convolutional neural network (2DConvNet) and demonstrated that the modern image recognition technology results in prediction accuracies comparable to the state-of-the-art cheminformatics tools. Furthermore, the performance of the image-based 2DConvNet model was comparatively evaluated on an external set of compounds from the Prestwick chemical library and resulted in experimental identification of significant and previously unreported antiandrogen potentials for several well-established generic drugs.},
	number = {8},
	journal = {Journal of chemical information and modeling},
	author = {Fernandez, Michael and Ban, Fuqiang and Woo, Godwin and Hsing, Michael and Yamazaki, Takeshi and LeBlanc, Eric and Rennie, Paul S. and Welch, William J. and Cherkasov, Artem},
	month = aug,
	year = {2018},
	pages = {1533--1543},
}

@article{ewart_navigating_2017,
	title = {Navigating tissue chips from development to dissemination: {A} pharmaceutical industry perspective},
	volume = {242},
	doi = {10.1177/1535370217715441},
	abstract = {Tissue chips are poised to deliver a paradigm shift in drug discovery. By emulating human physiology, these chips have the potential to increase the predictive power of preclinical modeling, which in turn will move the pharmaceutical industry closer to its aspiration of clinically relevant and ultimately animal-free drug discovery. Despite the tremendous science and innovation invested in these tissue chips, significant challenges remain to be addressed to enable their routine adoption into the industrial laboratory. This article describes the main steps that need to be taken and highlights key considerations in order to transform tissue chip technology from the hands of the innovators into those of the industrial scientists. Written by scientists from 13 pharmaceutical companies and partners at the National Institutes of Health, this article uniquely captures a consensus view on the progression strategy to facilitate and accelerate the adoption of this valuable technology. It concludes that success will be delivered by a partnership approach as well as a deep understanding of the context within which these chips will actually be used.Impact statementThe rapid pace of scientific innovation in the tissue chip (TC) field requires a cohesive partnership between innovators and end users. Near term uptake of these human-relevant platforms will fill gaps in current capabilities for assessing important properties of disposition, efficacy and safety liabilities. Similarly, these platforms could support mechanistic studies which aim to resolve challenges later in development (e.g. assessing the human relevance of a liability identified in animal studies). Building confidence that novel capabilities of TCs can address real world challenges while they themselves are being developed will accelerate their application in the discovery and development of innovative medicines. This article outlines a strategic roadmap to unite innovators and end users thus making implementation smooth and rapid. With the collective contributions from multiple international pharmaceutical companies and partners at National Institutes of Health, this article should serve as an invaluable resource to the multi-disciplinary field of TC development.},
	number = {16},
	journal = {Experimental Biology and Medicine},
	author = {Ewart, Lorna and Fabre, Kristin and Chakilam, Ananthsrinivas and Dragan, Yvonne and Duignan, David B. and Eswaraka, Jeetu and Gan, Jinping and Guzzie-Peck, Peggy and Otieno, Monicah and Jeong, Claire G. and Keller, Douglas A. and de Morais, Sonia M. and Phillips, Jonathan A. and Proctor, William and Sura, Radhakrishna and Van Vleet, Terry and Watson, David and Will, Yvonne and Tagle, Danilo and Berridge, Brian},
	year = {2017},
	keywords = {Tissue chips,microphysiological systems,toxicology,pharmacokinetics,innovation,partnership},
	pages = {1579--1585},
}

@techreport{ich_assessment_2017,
	title = {{ASSESSMENT} {AND} {CONTROL} {OF} {DNA} {REACTIVE} ({MUTAGENIC}) {IMPURITIES} {IN} {PHARMACEUTICALS} {TO} {LIMIT} {POTENTIAL} {CARCINOGENIC} {RISK}},
	institution = {ICH},
	author = {ICH},
	editor = {INTERNATIONAL COUNCIL FOR HARMONISATION OF TECHNICAL REQUIREMENTS FOR PHARMACEUTICALS FOR HUMAN USE (ICH)},
	year = {2017},
}

@article{patlewicz_can_2010,
	title = {Can mutagenicity information be useful in an {Integrated} {Testing} {Strategy} ({ITS}) for skin sensitization?},
	volume = {21},
	issn = {1062-936X},
	doi = {10.1080/1062936X.2010.528447},
	abstract = {Our previous work has investigated the utility of mutagenicity data in the development and application of Integrated Testing Strategies (ITS) for skin sensitization by focusing on the chemical mechanisms at play and substantiating these with experimental data where available. The hybrid expert system TIMES (Tissue Metabolism Simulator) was applied in the identification of the chemical mechanisms since it encodes a comprehensive set of established structure-activity relationships for both skin sensitization and mutagenicity. Based on the evaluation, the experimental determination of mutagenicity was thought to be potentially helpful in the evaluation of skin sensitization potential. This study has evaluated the dataset reported by Wolfreys and Basketter (Cutan. Ocul. Toxicol. 23 (2004), pp. 197-205). Upon an update of the experimental data, the original reported concordance of 68\% was found to increase to 88\%. There were several compounds that were 'outliers' in the two experimental evaluations which are discussed from a mechanistic basis. The discrepancies were found to be mainly associated with the differences between skin and liver metabolism. Mutagenicity information can play a significant role in evaluating sensitization potential as part of an ITS though careful attention needs to be made to ensure that any information is interpreted in the appropriate context.},
	number = {7-8},
	journal = {SAR and QSAR in environmental research},
	author = {Patlewicz, G. and Mekenyan, O. and Dimitrova, G. and Kuseva, C. and Todorov, M. and Kotov, S. and Stoeva, S. and Donner, E. M.},
	year = {2010},
	keywords = {(Q)SAR, Artificial intelligence, Computational biology, Experimental data, Integrated Testing Strategy (ITS), Integration testing, Mutagenicity Tests, Mutagens - chemistry, Mutagens - toxicity, Quantitative Structure-Activity Relationship, REACH, Sensitization, Skin - drug effects, Skin Tests - methods, Skin sensitization, TIMES, Tissue metabolism, mutagenicity},
	pages = {619--656},
}

@article{xu_deep_2015,
	title = {Deep {Learning} for {Drug}-{Induced} {Liver} {Injury}},
	volume = {55},
	issn = {1549-9596},
	doi = {10.1021/acs.jcim.5b00238},
	abstract = {Drug-induced liver injury (DILI) has been the single most frequent cause of safety-related drug marketing withdrawals for the past 50 years. Recently, deep learning (DL) has been successfully applied in many fields due to its exceptional and automatic learning ability. In this study, DILI prediction models were developed using DL architectures, and the best model trained on 475 drugs predicted an external validation set of 198 drugs with an accuracy of 86.9\%, sensitivity of 82.5\%, specificity of 92.9\%, and area under the curve of 0.955, which is better than the performance of previously described DILI prediction models. Furthermore, with deep analysis, we also identified important molecular features that are related to DILI. Such DL models could improve the prediction of DILI risk in humans. The DL DILI prediction models are freely available at http://www.repharma.cn/DILIserver/DILI\_home.php.},
	number = {10},
	journal = {Journal of chemical information and modeling},
	author = {Xu, Youjun and Dai, Ziwei and Chen, Fangjin and Gao, Shuaishi and Pei, Jianfeng and Lai, Luhua},
	year = {2015},
	keywords = {Algorithms, Artificial intelligence, Chemical and Drug Induced Liver Injury, Computer architecture, Drugs, Glycine - chemistry, Humans, Models, Biological, ROC Curve, Risk Factors, Safety-Based Drug Withdrawals, Software - standards},
	pages = {2085--2093},
}

@article{fourches_trust_2010,
	title = {Trust, {But} {Verify}: {On} the {Importance} of {Chemical} {Structure} {Curation} in {Cheminformatics} and {QSAR} {Modeling} {Research}},
	volume = {50},
	issn = {1549-9596},
	doi = {10.1021/ci100176x},
	abstract = {Molecular modelers and cheminformaticians typically analyze experimental data generated by other scientists. Consequently, when it comes to data accuracy, cheminformaticians are always at the mercy of data providers who may inadvertently publish (partially) erroneous data. Thus, dataset curation is crucial for any cheminformatics analysis such as similarity searching, clustering, QSAR modeling, virtual screening, etc., especially nowadays when the availability of chemical datasets in public domain has skyrocketed in recent years. Despite the obvious importance of this preliminary step in the computational analysis of any dataset, there appears to be no commonly accepted guidance or set of procedures for chemical data curation. The main objective of this paper is to emphasize the need for a standardized chemical data curation strategy that should be followed at the onset of any molecular modeling investigation. Herein, we discuss several simple but important steps for cleaning chemical records in a database including the removal of a fraction of the data that cannot be appropriately handled by conventional cheminformatics techniques. Such steps include the removal of inorganic and organometallic compounds, counterions, salts and mixtures; structure validation; ring aromatization; normalization of specific chemotypes; curation of tautomeric forms; and the deletion of duplicates. To emphasize the importance of data curation as a mandatory step in data analysis, we discuss several case studies where chemical curation of the original “raw” database enabled the successful modeling study (specifically, QSAR analysis) or resulted in a significant improvement of model's prediction accuracy. We also demonstrate that in some cases rigorously developed QSAR models could be even used to correct erroneous biological data associated with chemical compounds. We believe that good practices for curation of chemical records outlined in this paper will be of value to all scientists working in the fields of molecular modeling, cheminformatics, and QSAR studies.},
	number = {7},
	journal = {Journal of chemical information and modeling},
	author = {Fourches, Denis and Muratov, Eugene and Tropsha, Alexander},
	year = {2010},
	keywords = {Animals, Chemistry, Chemistry, Medicinal, Chemistry, Multidisciplinary, Computer Science, Computer Science, Information Systems, Computer Science, Interdisciplinary Applications, Exact sciences and technology, General and physical chemistry, General. Nomenclature, chemical documentation, computer chemistry, Life Sciences \& Biomedicine, Models, Chemical, Molecular Structure, Organometallic Compounds - chemistry, Pharmacology \& Pharmacy, Physical Sciences, Quantitative Structure-Activity Relationship, Science \& Technology, Technology, Theory of reactions, general kinetics. Catalysis. Nomenclature, chemical documentation, computer chemistry},
	pages = {1189--1204},
}

@article{shanks_are_2009,
	title = {Are animal models predictive for humans?},
	volume = {4},
	issn = {1747-5341},
	doi = {10.1186/1747-5341-4-2},
	abstract = {It is one of the central aims of the philosophy of science to elucidate the meanings of scientific terms and also to think critically about their application. The focus of this essay is the scientific term predict and whether there is credible evidence that animal models, especially in toxicology and pathophysiology, can be used to predict human outcomes. Whether animals can be used to predict human response to drugs and other chemicals is apparently a contentious issue. However, when one empirically analyzes animal models using scientific tools they fall far short of being able to predict human responses. This is not surprising considering what we have learned from fields such evolutionary and developmental biology, gene regulation and expression, epigenetics, complexity theory, and comparative genomics.},
	language = {eng},
	journal = {Philos Ethics Humanit Med},
	author = {Shanks, N. and Greek, R. and Greek, J.},
	month = jan,
	year = {2009},
	pmcid = {PMC2642860},
	keywords = {*Forecasting, *Models, Animal, Animal Experimentation, Animals, Humans},
	pages = {2},
}

@article{scarselli_graph_2009,
	title = {The {Graph} {Neural} {Network} {Model}},
	volume = {20},
	issn = {1045-9227},
	doi = {10.1109/TNN.2008.2005605},
	abstract = {Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function tau(G,n) isin IR m that maps a graph G and one of its nodes n into an m -dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.},
	number = {1},
	journal = {IEEE transactions on neural networks},
	author = {Scarselli, F. and Gori, M. and Ah Chung, Tsoi and Hagenbuchner, M. and Monfardini, G.},
	year = {2009},
	keywords = {Algorithms, Applied sciences, Artificial Intelligence, Artificial neural network, Biological system modeling, Biology, Chemistry, Computational efficiency, Computer science, Computer vision, Connectionism. Neural networks, Cycle graph, Data engineering, Data mining, Data processing. List processing. Character string processing, Databases, Factual, Directed acyclic graph, Directed graph, Euclidean space, Exact sciences and technology, Graph, Graph (abstract data type), Graph theory, Graphic methods, Graphical domains, Graphs, Internet, Learning, Linear Models, Mathematical analysis, Mathematical models, Memory organisation. Data processing, Methods, Moral graph, Neural Networks (Computer), Neural networks, Nonlinear Dynamics, Null graph, Null model, Parameter estimation, Pattern Recognition, Automated, Pattern recognition, Pattern recognition. Digital image processing. Computational geometry, Random geometric graph, Regression Analysis, Reproducibility of Results, Software, Supervised learning, Theoretical computer science, Voltage graph, control theory, graph neural networks (GNNs), graph processing, recursive neural networks, systems},
	pages = {61--80},
}

@article{hansen_benchmark_2009,
	title = {Benchmark data set for in silico prediction of {Ames} mutagenicity},
	volume = {49},
	issn = {1549-960X},
	doi = {10.1021/ci900161g},
	abstract = {Up to now, publicly available data sets to build and evaluate Ames mutagenicity prediction tools have been very limited in terms of size and chemical space covered. In this report we describe a new unique public Ames mutagenicity data set comprising about 6500 nonconfidential compounds (available as SMILES strings and SDF) together with their biological activity. Three commercial tools (DEREK, MultiCASE, and an off-the-shelf Bayesian machine learner in Pipeline Pilot) are compared with four noncommercial machine learning implementations (Support Vector Machines, Random Forests, k-Nearest Neighbors, and Gaussian Processes) on the new benchmark data set.},
	number = {9},
	journal = {Journal of chemical information and modeling},
	author = {Hansen, Katja and Mika, Sebastian and Schroeter, Timon and Sutter, Andreas and ter Laak, Antonius and Steger-Hartmann, Thomas and Heinrich, Nikolaus and Müller, Klaus-Robert},
	year = {2009},
	keywords = {Artificial Intelligence, Benchmarking, Computational Biology, Databases, Factual, Mutagenicity Tests - methods, Mutagenicity Tests - standards, Mutagens - chemistry, Mutagens - toxicity, Normal Distribution, Salmonella typhimurium - drug effects, Salmonella typhimurium - genetics, Structure-Activity Relationship},
	pages = {2077},
}

@article{assis_human_2009,
	title = {Human drug hepatotoxicity: a contemporary clinical perspective},
	volume = {5},
	issn = {1742-5255},
	doi = {10.1517/17425250902927386},
	abstract = {Background: Drug-induced liver injury (DILI) constitutes a significant medical challenge. The rising number of marketed drugs, aging population and polypharmacy make it imperative to understand the clinical presentation of DILI and the processes used in the assessment of causality and early detection. Objective: This article reviews the current clinical understanding of DILI including presentation patterns, causality assessment, risk factor ascertainment and early detection strategies including liver test monitoring. Significant initiatives such as the Drug-Induced Liver Injury Network (DILIN) are also discussed. Methods: A narrative review of clinical studies of DILI, with emphasis on clinical features, causality and surveillance. Conclusion: DILI remains a serious challenge in contemporary clinical practice. Further research and collaboration in the areas of epidemiology, causality and early detection are required to enhance the diagnosis and management of DILI.},
	number = {5},
	journal = {Expert Opinion on Drug Metabolism \& Toxicology},
	author = {Assis, David N. and Navarro, Victor J.},
	year = {2009},
	keywords = {Adverse Drug Reaction Reporting Systems, Age Factors, Chemical and Drug Induced Liver Injury, Clinical Trials as Topic, DILI, DILIN, Drug-Related Side Effects and Adverse Reactions, Humans, Liver Diseases - diagnosis, Liver Diseases - epidemiology, Liver Function Tests, Polypharmacy, RUCAM, Risk Factors, United States - epidemiology, causality assessment, drug hepatotoxicity, early detection},
	pages = {463--473},
}

@article{demsar_statistical_2006,
	title = {Statistical comparisons of classifiers over multiple data sets},
	volume = {7},
	issn = {1533-7928},
	abstract = {While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD ( critical difference) diagrams.},
	journal = {Journal of machine learning research},
	author = {Demsar, J.},
	year = {2006},
	keywords = {Automation \& Control Systems, Comparative studies, Computer Science, Computer Science, Artificial Intelligence, Friedman test, Multiple comparisons tests, Science \& Technology, Statistical methods, Technology, Wilcoxon signed ranks test},
	pages = {1--30},
}

@article{jemnitz_comparative_2004,
	title = {Comparative study in the {Ames} test of benzo[a]pyrene and 2‐aminoanthracene metabolic activation using rat hepatic {S9} and hepatocytes following in vivo or in vitro induction},
	volume = {19},
	issn = {0267-8357},
	doi = {10.1093/mutage/geh026},
	abstract = {We studied the replacement of hepatic S9 with in vivo and in vitro induced hepatocytes as a metabolic activation system with the aim of broadening the possibilities of mutagenic assays. Rats were pretreated with β‐naphthoflavone (BNF), phenobarbital (PB), 3‐methylcholanthrene (MC) and a combination of BNF and PB (BNF + PB). Mutagenic activation of benzo[a]pyrene (BP) and 2‐aminoanthracene (2AA) by hepatic S9 and hepatocytes was determined in the Ames test. Primary rat hepatocytes were used for in vitro induction and were used as the activating system in the Ames test. In vivo BNF treatment greatly increased the metabolic activation capacity of hepatic S9 and hepatocytes towards BP. With regard to 2AA activation, S9 and hepatocytes showed different BNF induction profiles. PB treatment reduced the mutagenicity of both compounds. Although ethoxyresorufin O‐dealkylase (EROD) activity of S9 from BNF + PB‐treated animals was almost 30‐fold greater than the control, its effectiveness in activation of 2AA was below the control level. A large part of the EROD activity of control cells was lost during culture, together with the ability to activate 2AA, however, 72 h of MC induction increased EROD activity to 200‐fold of the control, which corresponds to 28\% of that of in vivo induced hepatocytes. The mutagenic potential of BP activated by in vitro induced hepatocytes was 10‐fold above the control, which is 47\% of the mutagenicity detected following in vivo induction. In vitro induced hepatocytes increased 2AA mutagenicity to 14.6‐fold over the control, which corresponds to 68\% of in vivo induction. Our results suggest that primary culture of hepatocytes provides a useful model for the study of the role of metabolic activation processes concerning enzyme activity of cytochromes P450 and other metabolic enzymes and induction profiles of different inducers.},
	number = {3},
	journal = {Mutagenesis},
	author = {Jemnitz, Katalin and Veres, Zsuzsa and Torok, Geza and Toth, Eva and Vereczkey, Laszlo},
	year = {2004},
	keywords = {Ames test, Animals, Anthracenes - pharmacology, Benzo(a)pyrene, Benzo(a)pyrene - pharmacology, Biochemistry, Biological and medical sciences, Carcinogens - pharmacology, Cytochrome P450, Dose-Response Relationship, Drug, Enzyme, Enzyme assay, Fundamental and applied biological sciences. Psychology, Hepatocyte, Hepatocytes - drug effects, In vitro, In vivo, Male, Molecular and cellular biology, Molecular biology, Molecular genetics, Mutagenesis. Repair, Mutagenicity Tests, Mutagens - pharmacology, Rats, Rats, Wistar},
	pages = {245--250},
}

@article{amy_bainbridge_accc_2014,
	title = {{ACCC} recalls more jeans containing hazardous dye linked to cancer},
	journal = {ABC News},
	author = {Amy Bainbridge},
	month = may,
	year = {2014},
}

@misc{greg_landrum_rdkit_2012,
	type = {Repository of {Python3} {Code}},
	title = {{RDKit} - {MACCS} {Keys} {Implementation}},
	author = {Greg Landrum},
	year = {2012},
}

@techreport{ich_ich_2013,
	title = {{ICH} guideline {S2} ({R1}) on genotoxicity testing and data interpretation for pharmaceuticals intended for human use},
	institution = {ICH},
	author = {ICH},
	editor = {INTERNATIONAL COUNCIL FOR HARMONISATION OF TECHNICAL REQUIREMENTS FOR PHARMACEUTICALS FOR HUMAN USE (ICH)},
	year = {2013},
}

@article{walmsley_how_2011,
	title = {How accurate is in vitro prediction of carcinogenicity?},
	volume = {162},
	issn = {0007-1188 (Print) 0007-1188},
	doi = {10.1111/j.1476-5381.2010.01131.x},
	abstract = {Positive genetic toxicity data suggest carcinogenic hazard, and this can stop a candidate pharmaceutical reaching the clinic. However, during the last decade, it has become clear that many non-carcinogens produce misleading positive results in one or other of the regulatory genotoxicity assays. These doubtful conclusions cost a lot of time and money, as they trigger additional testing of apparently genotoxic candidates, both in vitro and in animals, to discover whether the suggested hazard is genuine. This in turn means that clinical trials can be put on hold. This review describes the current approaches to the 'misleading positive' problem as well as efforts to reduce the use of animals in genotoxicity assessment. The following issues are then addressed: the application of genotoxicity testing screens earlier in development; the search for new or improved in vitro genotoxicity tests; proposed changes to the International Committee on Harmonisation guidance on genotoxicity testing [S2(R1)]. Together, developments in all these areas offer good prospects of a more rapid and cost-effective way to understand genetic toxicity concerns.},
	language = {eng},
	number = {6},
	journal = {British journal of pharmacology},
	author = {Walmsley, R. M. and Billinton, N.},
	month = mar,
	year = {2011},
	pmcid = {PMC3058158},
	keywords = {*Carcinogenicity Tests, *Carcinogens, *Drug Discovery, *Mutagenicity Tests, Animals, DNA Damage, Drug Evaluation, Preclinical, False Positive Reactions, Guidelines as Topic, Neoplasms/chemically induced},
	pages = {1250--8},
}

@article{baxter_model_2011,
	title = {A {Model} of {Inductive} {Bias} {Learning}},
	doi = {10.48550/arXiv.1106.0245},
	abstract = {A major problem in machine learning is that of inductive bias: how to choose a learner's hypothesis space so that it is large enough to contain a solution to the problem being learnt, yet small enough to ensure reliable generalization from reasonably-sized training sets. Typically such bias is supplied by hand through the skill and insights of experts. In this paper a model for automatically learning bias is investigated. The central assumption of the model is that the learner is embedded within an environment of related learning tasks. Within such an environment the learner can sample from multiple tasks, and hence it can search for a hypothesis space that contains good solutions to many of the problems in the environment. Under certain restrictions on the set of all hypothesis spaces available to the learner, we show that a hypothesis space that performs well on a sufficiently large number of training tasks will also perform well when learning novel tasks in the same environment. Explicit bounds are also derived demonstrating that learning multiple tasks within an environment of related tasks can potentially give much better generalization than learning a single task.},
	author = {Baxter, J.},
	month = jun,
	year = {2011},
	keywords = {Computer Science - Artificial Intelligence},
	pages = {arXiv:1106.0245},
}

@article{rogers_extended-connectivity_2010,
	title = {Extended-{Connectivity} {Fingerprints}},
	volume = {50},
	issn = {1549-9596},
	doi = {10.1021/ci100050t},
	number = {5},
	journal = {Journal of chemical information and modeling},
	author = {Rogers, David and Hahn, Mathew},
	month = may,
	year = {2010},
	pages = {742--754},
}

@misc{pmlr-v9-glorot10a,
	address = {Proceedings of Machine Learning Research},
	title = {Understanding the difficulty of training deep feedforward neural networks},
	abstract = {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
	author = {Xavier Glorot and Yoshua Bengio and Yee Whye, Teh and Mike, Titterington},
	year = {2010},
}

@incollection{bolton_chapter_2008,
	title = {Chapter 12 - {PubChem}: {Integrated} {Platform} of {Small} {Molecules} and {Biological} {Activities}},
	volume = {4},
	isbn = {1574-1400},
	abstract = {PubChem is an open repository for experimental data identifying the biological activities of small molecules. PubChem contents include more than: 1000 bioassays, 28 million bioassay test outcomes, 40 million substance contributed descriptions, and 19 million unique compound structures contributed from over 70 depositing organizations. PubChem provides a significant, publicly accessible platform for mining the biological information of small molecules.},
	booktitle = {Annual {Reports} in {Computational} {Chemistry}},
	publisher = {Elsevier},
	author = {Bolton, Evan E. and Wang, Yanli and Thiessen, Paul A. and Bryant, Stephen H.},
	editor = {Wheeler, Ralph A. and Spellmeyer, David C.},
	month = jan,
	year = {2008},
	keywords = {Assay, Biological activity, Chemical structures, Database, PubChem, Repository, Web-based tools},
	pages = {217--241},
}

@article{kaplowitz_idiosyncratic_2005,
	title = {Idiosyncratic drug hepatotoxicity},
	volume = {4},
	issn = {1474-1784},
	doi = {10.1038/nrd1750},
	abstract = {Idiosyncratic drug hepatotoxicity is the main cause of compound failure in Phase II drug development and post-market drug withdrawals, label changes and use restrictions.The hallmark of idiosyncratic drug reactions is their occurrence in a unique, small proportion of individuals exposed to a drug, and much effort is focused on understanding what accounts for the uniqueness of an individual affected.Idiosyncrasy can be allergic or non-allergic depending on the presence of clinical features such as fever, rash, eosinophilia and other symptoms related to the adaptive immune system. Tools to diagnose allergic idiosyncratic hepatotoxicity are lacking but lymphocyte-stimulation tests show promise.Common to both types of idiosyncratic drug reaction is the occurrence of background mild liver injury, leading to the 'danger hypothesis', which suggests that a transient, mild liver injury might progress to severe drug-induced liver injury depending on genetic and environmental factors in concert with adaptive mechanisms such as inflammation and cell death.Measurement of serum alanine transferase is a sensitive indicator of liver function used in clinical trials and could be extended to monitoring liver toxicity for drugs on the market. However, this approach suffers from poor compliance, lack of proven efficacy and the possibility of withdrawing beneficial drugs from patients at low or no risk of toxicity.More knowledge of the clinical signatures of idiosyncratic drug reactions could help to predict hepatotoxicity in the absence of appropriate animal models, but is hindered by a lack of knowledge about the mechanisms of toxicity and the extent to which toxicity is drug-specific.The mechanism of hepatotoxicity of acetaminophen (paracetamol) in animal models and humans is well established and could be extrapolated to provide insights into idiosyncratic toxicity in humans, particularly the role of the innate immune system and cell-death pathways.Progress in understanding the causes of drug-induced idiosyncratic liver toxicity will require identification of specific determinants both in drug-metabolism pathways and in pathways involved in cell repair, regeneration and adaptation.},
	number = {6},
	journal = {Nature Reviews Drug Discovery},
	author = {Kaplowitz, Neil},
	month = jun,
	year = {2005},
	pages = {489--499},
}

@article{ashby_mechanistic_1993,
	title = {Mechanistic {Relationship} among {Mutagenicity}, {Skin} {Sensitization}, and {Skin} {Carcinogenicity}},
	volume = {101},
	issn = {0091-6765},
	doi = {10.1289/ehp.9310162},
	abstract = {Twenty organic Salmonella mutagens, seven of which (including benzo[a]pyrene) are established skin carcinogens, and one of which (2-chloroethanol) is a well-defined noncarcinogen to skin, have been evaluated for skin-sensitizing activity using the local lymph node assay. The relative mutagenicity of the agents to Salmonella was also established. Fourteen of the chemicals were positive in the local lymph node assay, including the seven skin carcinogens. 2-Chloroethanol was inactive as a sensitizing agent. We suggest that a variety of factors contributes to the lack of sensitizing activity of the remaining six bacterial mutagens: extremes of intrinsic chemical reactivity, high water solubility reducing dermal translocation, and inappropriate dermal metabolism. Two reference skin-sensitizing agents (an oxazolinone and fluorescein isothiocyanate) were established as in vitro clastogens after their recognition as nonmutagens to Salmonella. These data imply that mutagenicity, rather than simply activity in the Salmonella assay, is a primary stimulus for electrophilic sensitization and carcinogenic initiation in the skin. We conclude that genotoxicity data for an agent can provide indications of the agent's potential to induce skin sensitization and that genotoxins which are skin-sensitizing agents have an enhanced potential to initiate skin carcinogenesis. We suggest that common, albeit individually distinct, structure-activity relationships underpin genotoxicity, skin sensitization, and the initiation of skin carcinogenesis. These relationships should simplify the hazard evaluation of chemicals and contribute to a reduction in animal usage. Several predictions of skin carcinogenicity are made based on the data presented.},
	number = {1},
	journal = {Environmental health perspectives},
	author = {Ashby, John and Hilton, Jennifer and Dearman, Rebecca J. and Callander, Richard D. and Kimber, Ian},
	year = {1993},
	keywords = {Animals, Carcinogen, Carcinogenesis, Carcinogenicity, Carcinogenicity Tests, Carcinogens, Carcinogens - metabolism, Carcinogens - toxicity, Chemistry, Clastogen, DNA - drug effects, DNA - metabolism, Dermatitis, Contact - etiology, Dosage, Fluorescein isothiocyanate, Genotoxicity, Local lymph node assay, Lymph nodes, Lymphocyte Activation - drug effects, Mice, Mice, Inbred CBA, Mutagenicity, Mutagenicity Tests, Mutagens, Mutagens - adverse effects, Pathology, Pharmacology, Salmonella, Sensitization, Sensitizing, Skin, Skin Neoplasms - chemically induced, Skin Tests, integumentary system},
	pages = {62--67},
}

@article{lin_structureactivity_1988,
	title = {Structure—activity relationship studies on the mutagenicity of some azo dyes in the {Salmonella}/microsome assay},
	volume = {3},
	issn = {0267-8357},
	doi = {10.1093/mutage/3.4.311},
	abstract = {Analogs of Direct Black 19 and Direct Black 38 were synthesized and tested in the Salmonella/microsome assay. Those dyes which gave positive responses in strains TA98 and TA1538 would be expected to be metabolized to p-phenyl-enediamine by the liver microsomal enzymes (S9). Pure p-phenylenediamine is non-mutagenic in this assay but becomes mutagenic after it is oxidized. Thus the positive response of our synthetic azo compounds are most likely due to the formation of oxidized p-phenylenediamine. Modification of the moieties that can be metabolized to p-phenylenediamine by sulfonation, carboxylation or copper complexation eliminated the mutagenic responses.},
	number = {4},
	journal = {Mutagenesis},
	author = {Lin, George H. Y. and Solodar, Warren E.},
	year = {1988},
	keywords = {Ames test, Animals, Azo Compounds - metabolism, Azo Compounds - pharmacology, Bacteria, Biochemistry, Biological and medical sciences, Biotransformation, Carboxylation, Chemical mutagenesis, Chemistry, Coloring Agents - pharmacology, Enterobacteriaceae, Male, Medical sciences, Microbiology, Microsome, Microsomes, Liver - metabolism, Mutagenicity Tests, Mutagens, Positive response, Rats, Rats, Inbred Strains, Salmonella, Salmonella typhimurium - drug effects, Structure-Activity Relationship, Toxicology, food and beverages, fungi},
	pages = {311--315},
}

@article{durant_reoptimization_2002,
	title = {Reoptimization of {MDL} {Keys} for {Use} in {Drug} {Discovery}},
	volume = {42},
	issn = {0095-2338},
	doi = {10.1021/ci010132r},
	abstract = {For a number of years MDL products have exposed both 166 bit and 960 bit keysets based on 2D descriptors. These keysets were originally constructed and optimized for substructure searching. We report on improvements in the performance of MDL keysets which are reoptimized for use in molecular similarity. Classification performance for a test data set of 957 compounds was increased from 0.65 for the 166 bit keyset and 0.67 for the 960 bit keyset to 0.71 for a surprisal S/N pruned keyset containing 208 bits and 0.71 for a genetic algorithm optimized keyset containing 548 bits. We present an overview of the underlying technology supporting the definition of descriptors and the encoding of these descriptors into keysets. This technology allows definition of descriptors as combinations of atom properties, bond properties, and atomic neighborhoods at various topological separations as well as supporting a number of custom descriptors. These descriptors can then be used to set one or more bits in a keyset. We constructed various keysets and optimized their performance in clustering bioactive substances. Performance was measured using methodology developed by Briem and Lessel. “Directed pruning” was carried out by eliminating bits from the keysets on the basis of random selection, values of the surprisal of the bit, or values of the surprisal S/N ratio of the bit. The random pruning experiment highlighted the insensitivity of keyset performance for keyset lengths of more than 1000 bits. Contrary to initial expectations, pruning on the basis of the surprisal values of the various bits resulted in keysets which underperformed those resulting from random pruning. In contrast, pruning on the basis of the surprisal S/N ratio was found to yield keysets which performed better than those resulting from random pruning. We also explored the use of genetic algorithms in the selection of optimal keysets. Once more the performance was only a weak function of keyset size, and the optimizations failed to identify a single globally optimal keyset. Instead multiple, equally optimal keysets could be produced which had relatively low overlap of the descriptors they encoded.},
	number = {6},
	journal = {Journal of Chemical Information and Computer Sciences},
	author = {Durant, Joseph L. and Leland, Burton A. and Henry, Douglas R. and Nourse, James G.},
	year = {2002},
	keywords = {Algorithms, Chemistry, Chemistry, Multidisciplinary, Computational Biology - methods, Computer Science, Computer Science, Information Systems, Computer Science, Interdisciplinary Applications, Databases, Factual, Drug Evaluation, Preclinical - methods, Genetics, Pattern Recognition, Automated, Physical Sciences, Science \& Technology, Software, Structure-Activity Relationship, Technology},
	pages = {1273--1280},
}

@article{to_mutagenicity_1982,
	title = {Mutagenicity of trans-anethole, estragole, eugenol, and safrole in the {Ames} {Salmonella} typhimurium assay [{Flavoring} agents]},
	volume = {28},
	issn = {0007-4861},
	doi = {10.1007/BF01605630},
	number = {6},
	journal = {Bulletin of environmental contamination and toxicology},
	author = {To, L. P. and Hunt, T. P. and Andersen, M. E.},
	year = {1982},
	keywords = {Anethole, Animals, Anisoles - toxicity, Dioxoles - toxicity, Ecotoxicology, Estragole, Eugenol, Eugenol - toxicity, Food science, Mutagenicity Tests, Mutagens, Phosphoadenosine Phosphosulfate - metabolism, Rats, Safrole, Safrole - toxicity, Salmonella typhimurium - drug effects},
	pages = {647},
}

@article{maron_revised_1983,
	title = {Revised methods for the {Salmonella} mutagenicity test},
	volume = {113},
	issn = {0165-1161},
	doi = {10.1016/0165-1161(83)90010-9},
	abstract = {The methods for detecting carcinogens and mutagens with the Salmonella mutagenicity test were described previously (Ames et al., 1975b). The present paper is a revision of the methods. Two new tester strains, a frameshift strain (TA97) and a strain carrying an ochre mutation on a multicopy plasmid (TA102), are added to the standard tester set. TA97 replaces TA1537. TA1535 and TA1538 are removed from the recommended set but can be retained at the option of the investigator. TA98 and TA100 are retained. We discuss other special purpose strains and present some minor changes in procedure, principally in the growth, storage, and preservation of the tester strains. Two substitutions are made in diagnostic mutagens to eliminate MNNG and 9-aminoacridine. Some test modifications are discussed.},
	number = {3},
	journal = {Mutation Research/Environmental Mutagenesis and Related Subjects},
	author = {Maron, Dorothy M. and Ames, Bruce N.},
	year = {1983},
	pages = {173--215},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	issn = {1476-4687},
	doi = {10.1038/323533a0},
	abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
	number = {6088},
	journal = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	month = oct,
	year = {1986},
	pages = {533--536},
}

@article{y_tazima_consequences_1979,
	title = {Consequences of the {AF}-2 incident in {Japan}},
	volume = {29},
	doi = {doi:10.1289/ehp.7929183},
	abstract = {The discovery of the potent mutagenicity of AF-2, which was once used in Japan as a food preservative, has exerted a great influence not only on screening procedures for carcinogenic compounds but also on legislative approaches to mutagenic substances. It promoted the synthesis of exceedingly sensitive and reliable tester strains in Salmonella and supported the hypothesis of a common mechanism between mutagenicity and carcinogenicity. Thus preliminary screening for carcinogenic substances has become feasible using mutagenicity as an index. It also contributed greatly to the formulation of legislative measures for chemical substances which for the first time gave due attention to mutagenicity. Furthermore, the exposure of a large population to such a potent mutagen raised a question as to what extent the genetic constitution of the Japanese population might have been damaged. This suggested that urgent need for a system to monitor the total genetic damage to a human genome.},
	journal = {Environmental health perspectives},
	author = {Y Tazima},
	year = {1979},
	pages = {183--187},
}

@techreport{conover_multiple-comparisons_1979,
	address = {United States},
	title = {Multiple-comparisons procedures. {Informal} report},
	abstract = {Some of the more popular multiple-comparisons procedures are discussed and compared. Some new nonparametric methods are introduced. One procedure is an analog to the Fisher's least-significant-difference method for the completely randomized design. Some simulation studies indicate this procedure is a reasonable nonparametric method to use. A summary description is given for other nonparametric methods, which may be used with the completely randomized or randomized blocks designs. 3 tables.},
	language = {English},
	author = {Conover, W. J. and Iman, R. L.},
	year = {1979},
	keywords = {99 GENERAL AND MISCELLANEOUS//MATHEMATICS, COMPUTING, AND INFORMATION SCIENCE, 990200* - Mathematics \& Computers, CALCULATION METHODS, COMPARATIVE EVALUATIONS, MATHEMATICS, STATISTICS},
	pages = {Medium: ED; Size: Pages: 17},
}

@article{rogers_computer_1960,
	title = {A {Computer} {Program} for {Classifying} {Plants}},
	volume = {132},
	issn = {0036-8075},
	doi = {10.1126/science.132.3434.1115},
	journal = {Science},
	author = {Rogers, David J. and Tanimoto, Taffee T.},
	month = oct,
	year = {1960},
	pages = {1115--1118},
}
